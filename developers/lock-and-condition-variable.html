<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://schema.org/WebPage">
<head>
<meta http-equiv="X-UA-Compatible" content="chrome=1" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var e="wtsrt_",g="tbsd_",h="tbnd_",k="start",l="_wtsrt",m="_tbnd",n="CSI/";(function(){function f(a){this.t={};this.tick=function(a,c,b){this.t[a]=[void 0!=b?b:(new Date).getTime(),c];if(void 0==b)try{window.console.timeStamp(n+a)}catch(d){}};this.tick(k,null,a)}var a;window.performance&&(a=window.performance.timing);var p=a?new f(a.responseStart):new f;window.jstiming={Timer:f,load:p};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick(l,void 0,c),b.tick(e,l,d),b.tick(g,e))}try{a=null,
window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick(m,void 0,window.chrome.csi().startE),b.tick(h,m,c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick(m,void 0,window.external.startE),b.tick(h,m,c))),a&&(window.jstiming.pt=a)}catch(q){}})(); })()
</script>
<link rel="shortcut icon" href="../_/rsrc/1354323194313/favicon.ico" type="image/x-icon" />
<link rel="apple-touch-icon" href="https://ssl.gstatic.com/sites/p/56e332/system/app/images/apple-touch-icon.png" type="image/png" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var d="",g="__duration__",h="function";function k(c){return document.getElementById(c)}window.byId=k;function l(c){return c.replace(/^\s+|\s+$/g,d)}window.trim=l;var m=[],n=0;window.JOT_addListener=function(c,a,b){var e=new String(n++);c={eventName:c,handler:a,compId:b,key:e};m.push(c);return e};window.JOT_removeListenerByKey=function(c){for(var a=0;a<m.length;a++)if(m[a].key==c){m.splice(a,1);break}};
window.JOT_removeAllListenersForName=function(c){for(var a=0;a<m.length;a++)m[a].eventName==c&&m.splice(a,1)};window.JOT_postEvent=function(c,a,b){var e={eventName:c,eventSrc:a||{},payload:b||{}};if(window.JOT_fullyLoaded)for(a=m.length,b=0;b<a&&b<m.length;b++){var f=m[b];f&&f.eventName==c&&(e.listenerCompId=f.compId||d,(f=typeof f.handler==h?f.handler:window[f.handler])&&f(e))}else window.JOT_delayedEvents.push({eventName:c,eventSrc:a,payload:b})};window.JOT_delayedEvents=[];
window.JOT_fullyLoaded=!1;window.JOT_formatRelativeToNow=function(c,a){var b=((new Date).getTime()-c)/6E4;if(1440<=b||0>b)return null;var e=0;60<=b&&(b/=60,e=2);2<=b&&e++;return a?window.JOT_siteRelTimeStrs[e].replace(g,Math.floor(b)):window.JOT_userRelTimeStrs[e].replace(g,Math.floor(b))}; })()
</script>
<script>

  

  var breadcrumbs = [{"path":"/developers","deleted":false,"title":"For Developers","dir":"ltr"},{"path":"/developers/lock-and-condition-variable","deleted":false,"title":"Chrome C++ Lock and ConditionVariable","dir":"ltr"}];
  var JOT_clearDotPath = 'https://ssl.gstatic.com/sites/p/56e332/system/app/images/cleardot.gif';

  
  var JOT_userRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

  
  

  

  var webspace = {"enableAnalytics":true,"pageSharingId":"jotspot_page","enableUniversalAnalytics":false,"sharingPolicy":"OPENED_WITH_INDICATOR","siteTitle":"The Chromium Projects","isStartPageEnabled":true,"adsensePublisherId":null,"features":{"languageSelectDefaultTextSetToDefault":true,"validateClientGvizDataSourceUrls":true,"moreMobileStyleImprovements":true,"newInsertMenuIcons":true,"accessibleSortingButtons":true,"domainAnalyticsInGAOnly":true,"noCaptcha":true,"fileCabinetScreenReaderFix":true,"updatedTosAndPrivacyLinks":null,"pageDrafts":false,"mobileOrientationFix":true,"plusBadge":false,"pdfEmbedSupport":false,"jsClickFix":true},"isPublic":true,"isConsumer":false,"serverFlags":{"cajaBaseUrl":"//www.gstatic.com/caja","cajaDebugMode":false},"onepickBaseUrl":"https://docs.google.com","domainAnalyticsAccountId":"","plusPageId":"","signInUrl":"https://www.google.com/a/SelectSession?continue\u003dhttps://sites.google.com/a/chromium.org/dev/developers/lock-and-condition-variable\u0026service\u003djotspot","analyticsAccountId":"UA-5484340-1","scottyUrl":"/_/upload","homePath":"/","siteNoticeUrlEnabled":null,"plusPageUrl":"","adsensePromoClickedOrSiteIneligible":true,"csiReportUri":"https://gg.google.com/csi","sharingId":"jotspot","termsUrl":"//www.google.com/intl/en/policies/terms/","gvizVersion":1,"editorResources":{"sitelayout":["https://ssl.gstatic.com/sites/p/56e332/system/app/css/sitelayouteditor.css"],"text":["https://ssl.gstatic.com/sites/p/56e332/system/js/codemirror.js","https://ssl.gstatic.com/sites/p/56e332/system/app/css/codemirror_css.css","https://ssl.gstatic.com/sites/p/56e332/system/js/trog_edit__en.js","https://ssl.gstatic.com/sites/p/56e332/system/app/css/trogedit.css","/_/rsrc/1441580320000/system/app/css/editor.css","https://ssl.gstatic.com/sites/p/56e332/system/app/css/codeeditor.css","/_/rsrc/1441580320000/system/app/css/camelot/editor-jfk-wlb.css"]},"sharingUrlPrefix":"/_/sharing","isAdsenseEnabled":true,"domain":"chromium.org","baseUri":"","name":"dev","siteTemplateId":false,"siteNoticeRevision":null,"siteNoticeUrlAddress":null,"siteNoticeMessage":null,"page":{"isRtlLocale":false,"canDeleteWebspace":null,"isPageDraft":null,"parentPath":"/developers","parentWuid":"wuid:gx:982466121d9f2cd","siteLocale":"en","timeZone":"America/Los_Angeles","type":"text","title":"Chrome C++ Lock and ConditionVariable","locale":"en","wuid":"wuid:gx:4ff34d64e741f0d0","revision":28,"path":"/developers/lock-and-condition-variable","isSiteRtlLocale":false,"pageInheritsPermissions":null,"name":"lock-and-condition-variable","canChangePath":true,"state":"","properties":{},"bidiEnabled":false,"currentTemplate":{"path":"/system/app/pagetemplates/text","title":"Web Page"}},"canPublishScriptToAnyone":true,"user":{"keyboardShortcuts":true,"sessionIndex":"","guest_":true,"displayNameOrEmail":"guest","userName":"guest","uid":"","renderMobile":false,"domain":"","namespace":"","hasWriteAccess":false,"namespaceUser":false,"primaryEmail":"guest","hasAdminAccess":false},"gadgets":{"baseUri":"/system/app/pages/gadgets"}};
  webspace.page.breadcrumbs = breadcrumbs;

  
  var JOT_siteRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

</script>
<script type="text/javascript">
                window.jstiming.load.tick('scl');
              </script>
<meta name="title" content="Chrome C++ Lock and ConditionVariable - The Chromium Projects" />
<meta itemprop="name" content="Chrome C++ Lock and ConditionVariable - The Chromium Projects" />
<meta property="og:title" content="Chrome C++ Lock and ConditionVariable - The Chromium Projects" />
<meta name="description" content="Home of the Chromium Open Source Project" />
<meta itemprop="description" content="Home of the Chromium Open Source Project" />
<meta id="meta-tag-description" property="og:description" content="Home of the Chromium Open Source Project" />
<style type="text/css">
</style>
<link rel="stylesheet" type="text/css" href="https://ssl.gstatic.com/sites/p/56e332/system/app/themes/beigeandblue/standard-css-beigeandblue-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="../_/rsrc/1441580320000/system/app/css/overlay.css%3Fcb=beigeandblueundefineda100%2525%2525150goog-ws-leftthemedefaultstandard.css" />
<link rel="stylesheet" type="text/css" href="../_/rsrc/1441580320000/system/app/css/camelot/allthemes-view.css" />
<!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->
<title>Chrome C++ Lock and ConditionVariable - The Chromium Projects</title>
<meta itemprop="image" content="/_/rsrc/1438879449147/config/customLogo.gif?revision=3" />
<meta property="og:image" content="/_/rsrc/1438879449147/config/customLogo.gif?revision=3" />
<script type="text/javascript">
                window.jstiming.load.tick('cl');
              </script>
</head>
<body xmlns="http://www.google.com/ns/jotspot" id="body" class=" en            ">
<div id="sites-page-toolbar" class="sites-header-divider">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-status" class="sites-status" style="display:none;"><div id="sites-notice" class="sites-notice" role="status" aria-live="assertive"> </div></div>
</div>
<div id="sites-chrome-everything-scrollbar">
<div id="sites-chrome-everything" class="">
<div id="sites-chrome-page-wrapper" style="direction: ltr">
<div id="sites-chrome-page-wrapper-inside">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-chrome-header-wrapper" style="height:auto;">
<table id="sites-chrome-header" class="sites-layout-hbox" cellspacing="0" style="height:auto;">
<tr class="sites-header-primary-row" id="sites-chrome-userheader">
<td id="sites-header-title" class="" role="banner"><div class="sites-header-cell-buffer-wrapper"><a href="../index.html" id="sites-chrome-userheader-logo"><img id="logo-img-id" src="../_/rsrc/1438879449147/config/customLogo.gif%3Frevision=3" alt="The Chromium Projects" class="sites-logo  " /></a><h2><a href="../index.html" dir="ltr" id="sites-chrome-userheader-title">The Chromium Projects</a></h2></div></td><td class="sites-layout-searchbox  "><div class="sites-header-cell-buffer-wrapper"><form id="sites-searchbox-form" action="https://www.chromium.org/system/app/pages/search" role="search"><input type="hidden" id="sites-searchbox-scope" name="scope" value="search-site" /><input type="text" id="jot-ui-searchInput" name="q" size="20" value="" aria-label="Search this site" /><div id="sites-searchbox-button-set" class="goog-inline-block"><div role="button" id="sites-searchbox-search-button" class="goog-inline-block jfk-button jfk-button-standard" tabindex="0">Search this site</div></div></form></div></td>
</tr>
<tr class="sites-header-secondary-row" id="sites-chrome-horizontal-nav">
<td colspan="2" id="sites-chrome-header-horizontal-nav-container" role="navigation">
</td>
</tr>
</table>
</div>
<div id="sites-chrome-main-wrapper">
<div id="sites-chrome-main-wrapper-inside">
<table id="sites-chrome-main" class="sites-layout-hbox" cellspacing="0" cellpadding="{scmCellpadding}" border="0">
<tr>
<td id="sites-chrome-sidebar-left" class="sites-layout-sidebar-left initial" style="width:150px">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_7648876402527094" class="sites-embed" role="navigation"><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="../chromium-projects.html" jotId="wuid:gx:10ae433dadbbab13" class="sites-navigation-link">Home</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../Home.1.html" jotId="wuid:gx:43582b9d2029d3af" class="sites-navigation-link">Chromium</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../chromium-os.1.html" jotId="wuid:gx:83df2ab1f8880ba" class="sites-navigation-link">Chromium OS</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_14720868319272995" class="sites-embed" role="navigation"><h4 class="sites-embed-title">Quick links</h4><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="../for-testers/bug-reporting-guidelines.html" class="sites-navigation-link">Report bugs</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="discussion-groups.html" class="sites-navigation-link">Discuss</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../system/app/pages/sitemap/hierarchy.html" jotId="wuid:gx:4b58a9a350ad12f" class="sites-navigation-link">网站地图</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_19690813310444355" class="sites-embed" role="navigation"><h4 class="sites-embed-title">Other sites</h4><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="http://blog.chromium.org/" class="sites-navigation-link">Chromium Blog</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="http://code.google.com/chrome/extensions/" class="sites-navigation-link">Google Chrome Extensions</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="https://developers.google.com/chrome/chrome-frame/" class="sites-navigation-link">Google Chrome Frame</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_19695218559354544" class="sites-embed" role="complementary"><h4 class="sites-embed-title"></h4><div class="sites-embed-content sites-embed-content-sidebar-textbox"><div dir="ltr"><span style="font-size:x-small">Except as otherwise </span><a href="http://developers.google.com/site-policies.html#restrictions"><span style="font-size:x-small">noted</span></a><span style="font-size:x-small">, the content of this page is licensed under a </span><a href="http://creativecommons.org/licenses/by/2.5/"><span style="font-size:x-small">Creative Commons Attribution 2.5 license</span></a><span style="font-size:x-small">, and examples are licensed under the </span><a href="http://src.chromium.org/viewvc/chrome/trunk/src/LICENSE" target="_blank"><span style="font-size:x-small">BSD License</span></a><span style="font-size:x-small">.<br /></span></div></div></div>
</td>
<td id="sites-canvas-wrapper">
<div id="sites-canvas" role="main">
<div id="goog-ws-editor-toolbar-container"> </div>
<div xmlns="http://www.w3.org/1999/xhtml" id="title-crumbs" style="">
<A href="../developers.1.html" dir="ltr">For Developers</A>‎ &gt; ‎
  </div>
<h3 xmlns="http://www.w3.org/1999/xhtml" id="sites-page-title-header" style="" align="left">
<span id="sites-page-title" dir="ltr" tabindex="-1" style="outline: none">Chrome C++ Lock and ConditionVariable</span>
</h3>
<div id="sites-canvas-main" class="sites-canvas-main">
<div id="sites-canvas-main-content">
<table xmlns="http://www.w3.org/1999/xhtml" cellspacing="0" class="sites-layout-name-one-column sites-layout-hbox"><tbody><tr><td class="sites-layout-tile sites-tile-name-content-1"><div dir="ltr"><h1><a name="TOC-First-a-warning:-do-really-you-need-Locking-or-CondVars-"></a><font size="4">First a warning: do really you need Locking or CondVars?</font></h1>
<p>Are you sure you need to use explicit locking and condition variables? In Chrome code, message passing is far more common
(via <code>TaskRunner</code> and <code>PostTask</code>) and low-level
primitives like locks and condition variables should be used only when
necessary.</p><p>Some additional motivation:</p><ul><li><span style="color:rgb(34,34,34);font-family:arial,sans-serif;font-size:13px;background-color:rgba(255,255,255,0.917969)">Condition variables are nearly impossible to implement correctly on </span><span style="background-color:rgba(255,255,255,0.917969)"><font color="#222222" face="arial, sans-serif" size="2">Windows XP or earlier. Our implementation is correct, but </font></span><span style="background-color:rgba(255,255,255,0.917969)"><font color="#222222" face="arial, sans-serif" size="2">_very_ slow. Whenever you use a CV you are disproportionately harming our performance on Windows</font></span><span style="color:rgb(34,34,34);font-family:arial,sans-serif;font-size:13px;background-color:rgba(255,255,255,0.917969)">.</span></li><li><span style="color:rgb(34,34,34);font-family:arial,sans-serif;font-size:13px;background-color:rgba(255,255,255,0.917969)">A lot of times people just want to wait on a boolean.  In such cases, if message passing cannot work, please use WaitableEvent instead.</span><font color="#222222" face="arial, sans-serif" size="2"><br /></font></li></ul>
<p>
But for the times when you <em>do</em> need to use locks and condition
variables, this document will explain the best practices and pitfalls
in using them.

</p>
<small>(Much of the below was originally written by Mike Burrows.)</small>
<small>(TODO: Figure out how to get anchor links to work)</small>
<h2><a name="TOC-Using-Lock-and-ConditionVariable"></a>Using <code>Lock</code> and <code>ConditionVariable</code></h2>
<h3><a name="TOC-Terminology-and-basics"></a>Terminology and basics</h3>
<p>
The <code>Lock</code> class implements a <i>mut</i>ual <i>ex</i>clusion lock,
or <i>mutex</i> for short.  A mutex is used to permit only one thread at a time
to have exclusive access to some resource, which is typically some variable or
data structure.  Mutexes are so common that many words have been coined to
describe their operation.

</p>
<p>
Each <code>Lock</code> <code>mu</code> has two basic operations:  <code>mu.Acquire()</code> and
<code>mu.Release()</code>.  Conceptually, it has just a single bit of abstract state:  the
boolean <code>mu.held</code>.  When <code>mu</code> is created, <code>mu.held</code> is <code>false</code>
and <code>mu</code> is said to be <i>free</i> or <i>unlocked</i>.  
<code>mu.Acquire()</code> blocks the caller until some moment when <code>mu</code> is free, and then
atomically changes <code>mu.held</code> from <code>false</code> to <code>true</code>; <code>mu</code> is then said to
be <i>held</i> or <i>locked</i> by the caller.  <code>mu.Release()</code> sets
<code>mu.held</code> to <code>false</code> once more. 

</p>
<p>
Calling <code>mu.Acquire()</code> is often referred to as
<i>locking</i> or <i>acquiring</i> <code>mu</code>, while calling <code>mu.Release()</code>
is referred to as <i>unlocking</i> or <i>releasing</i> <code>mu</code>.
An action performed by a thread while holding <code>mu</code> is said to be performed
<i>under</i> <code>mu</code>.  Data structures manipulated under <code>mu</code>, and
their invariants, are said to be <i>protected by</i> <code>mu</code>.

</p>
<p>
Clients of <code>Lock</code> must obey these rules:
</p>
<ol>
<li> Each time a thread acquires <code>mu</code> it must later release <code>mu</code>.
</li>
<li> A thread may not attempt to release <code>mu</code> unless it holds <code>mu</code>.
</li>
</ol>
<p>
Because <code>mu.Acquire()</code> acts atomically to change the state of <code>mu.held</code>
we are guaranteed that, if these rules are followed, only one thread may hold <code>mu</code>
at any given time.

</p>
<p>
These rules are best followed by bracketing regions of code with matching
calls to <code>mu.Acquire()</code> and <code>mu.Release()</code> in the same procedure.
Such sections of code are called <i>critical regions</i> or <i>critical
sections</i>, or occasionally <a href="lock-and-condition-variable.html#monitors"><i>monitors</i></a> after Hoare monitors,
from which
mutexes were derived.  (A Hoare monitor is an abstraction that automatically
acquires a lock on entry and releases it on exit.)  In Chrome C++ code, many
use the idiom <code>AutoLock l(mu)</code>, which acquires
<code>mu</code> and releases it when <code>l</code> goes out of
scope. (Less commonly, <code>AutoUnlock l(mu)</code> can also be
used.)

</p>
<p>
Mutexes perform two tasks in concurrent programming.  Their primary role is to
protect the invariants of variables and data structures manipulated by multiple
threads (these invariants are often called <i>monitor invariants</i>, again
recalling the work of Hoare).  The programmer is required to establish the
invariant before releasing the mutex; he can then assume the invariant holds whenever
he acquires the mutex, even if his updates <i>temporarily</i> invalidate the
invariant during the critical section.  One cannot guarantee
the invariant is true in a thread that does not hold the mutex, because
the mutex holder may be changing the monitored state at that moment.
For example, suppose <code>Lock mu</code> protects the invariant that
<code>a + b == 0</code>.  This code is
then legal:
</p>
<pre>  mu.Acquire();
  assert(a + b == 0); // invariant assumed to hold
  a++;        // invariant temporarily invalidated
  b--;        // invariant restored before mu is released
  mu.Release();
</pre>
while this code is erroneous:
<pre>  mu.Acquire();
  assert(a + b == 0); // invariant assumed to hold
  a++;          // invariant invalidated
  mu.Release(); // BUG: mu released while invariant invalid
  mu.Acquire();
  b--;          // attempt to restore the invariant, but the damage is already done
  mu.Release();
</pre>
The following does not invalidate the invariant,
but incorrectly assumes it is true when the lock is not held:
<pre>  mu.Acquire();
  assert(a + b == 0); // correct: invariant assumed to hold
  mu.Release();
  assert(a + b == 0); // BUG: can't assume invariant without lock
</pre>
The invariant holds only when evaluated on state observed
in a single critical section:
<pre>  mu.Acquire();
  assert(a + b == 0); // correct: invariant assumed to hold
  temp = a;           // takes a temporary copy of "a"
  mu.Release();
  mu.Acquire();
  assert(temp + b == 0); // BUG: can't assume invariant on state
                         // from two distinct critical sections
  mu.Release();
</pre>
<p>
A less obvious role of mutexes is to ensure a sequentially-consistent
view of such data structures on machines with
memory systems that are
not sequentially consistent. Mutexes also prevent compiler reordering which could otherwise cause race conditions.

</p>
<h3><a name="TOC-Other-properties-of-Lock"></a>Other properties of <code>Lock</code></h3>
<ul>
<li>
<p>
The call <code>mu.Try()</code> either returns <code>false</code> or
acquires <code>mu</code> and returns <code>true</code>.  It does not block.
If <code>mu</code> is free, it is unlikely to return <code>false</code>.
</p>
</li>
<li>
<p>
The call <code>mu.AssertAcquired()</code> aborts the process in debug mode if <code>mu</code>
is not held by the calling thread..
</p>
<p>
</p>
</li>
<li>
<p><code>Lock</code> is able to synchronize its own deletion.  For example, if an object
<code>*o</code> contains a <code>Lock</code> <code>mu</code> and a
correctly-maintained reference count <code>c</code>, this code is safe:
</p>
<pre>  o-&gt;mu.Acquire();
  bool del = (--(o-&gt;c) == 0);
  o-&gt;mu.Release();
  if (del) { delete o; }
</pre>
Not all lock implementations have this property, so it should not be taken for
granted when porting code.  (To provide this property, we 
guarantee that <code>mu.Release()</code> does not touch <code>mu</code> after the
atomic moment at which <code>mu</code> becomes free.)
</li>
<li>
<p>
<code>Lock</code> is not re-entrant (also known as not recursive).  See <a href="lock-and-condition-variable.html#reentrant">below</a>.
</p>
</li></ul>
<h3><a name="TOC-Condition-variables"></a>Condition variables</h3>

Condition variables are a means for blocking a thread until some condition has been satisfied.  Viewed in isolation, a condition variable allows threads to block and to be
woken by other threads.  However, condition variables are designed to be used
in a specific way; a condition variable interacts with a mutex to make it easy
to wait for an
<a href="lock-and-condition-variable.html#condprotect">arbitrary condition on state protected by the mutex</a>.
Chrome's C++ condition variables have type <code>ConditionVariable</code>.
<p>
Suppose that a thread is to wait for some boolean expression <i>cond_expr</i>
to become true, where the state associated with <i>cond_expr</i> is
protected by <code>Lock mu</code>.
The programmer would write:
</p>
<pre>  // Waiter
  mu.Acquire();
  while (!cond_expr) {
    cv.Wait();  // mu was passed to cv's constructor
  }
  // cond_expr now holds
  ...
  mu.Release();
</pre>

The <code>Wait()</code> call atomically unlocks <code>mu</code> (which the thread must hold),
and blocks on the condition variable <code>cv</code>.  When another thread signals
the condition variable, the thread will reacquire the <code>mu</code>, and
go around the <a href="lock-and-condition-variable.html#whileloop">mandatory while-loop</a> to recheck <i>cond_expr</i>. 
<p>
Another thread that  makes <i>cond_expr</i> true might execute:
</p>
<pre>  // Waker
  mu.Acquire();
  Make_cond_expr_True();
  // cond_expr now holds
  cv.Signal();
  mu.Release();
</pre>
The call to <code>Signal()</code> wakes at least one of the threads waiting on
<code>cv</code>.  Many threads may be blocked on a condition variable at any
given time; if it makes sense to wake more than one such thread
<code>Broadcast()</code> can be used. (However, this may lead to
contention and poor performance if all waiting threads use the same
lock; a possibly better approach to getting a lot of threads out of
<code>Wait()</code> is to have each thread (upon
exiting <code>Wait()</code>) call <code>Signal()</code> to free up
another <code>Wait()</code>ing thread.)

<p>
A single condition variable can be used by threads waiting for 
different conditions.  However, in this case, <code>Broadcast()</code> <i>must</i> be used
when any of the conditions becomes true, because the <code>ConditionVariable</code> implementation
cannot otherwise guarantee to wake the correct thread.  It can be more efficient
to use one condition variable for each different condition;
any number of condition variables can be used with a single mutex.

</p>
<p>
Both <code>Signal()</code> and <code>Broadcast()</code> are
efficient if there are no threads to wake.  (TODO: verify this)  Clients should call
<code>Signal()</code> or <code>Broadcast()</code> <a href="http://www.chromium.org/developers/lock-and-condition-variable#TOC-Why-put-Signal-inside-the-critical-section-">inside the critical section</a>
that makes the condition true.

</p>
<p>
The call <code>TimedWait()</code> allows a thread to wait until
either a condition is true, or until some time has elapsed.
Like <code>Wait()</code>, <code>TimedWait()</code> <i>always</i> reacquires
the mutex before returning.  Example use:
</p>
<pre>  static const int64 kMSToWait = 1000;  // we'll wait at most 1000ms
  TimeDelta left_to_wait = TimeDelta::FromMilliseconds(kMSToWait);  // ms to wait at any given time
  Time deadline = Time::Now() + left_to_wait;
  mu.Acquire();
  while (!cond_expr &amp;&amp; left_to_wait.InMilliseconds() &gt; 0) {
    cv.TimedWait(left_to_wait);
    left_to_wait = deadline - Time::Now();
  }
  if (cond_expr) {
    // cond_expr true
  } else {
    // cond_expr false; 1000ms timeout expired
  }
  mu.Release();
</pre>
<h3><a name="TOC-Recommended-usage"></a>Recommended usage</h3>

Variables accessed by more than one thread and written
by at least one thread should be protected consistently by a <code>Lock</code>.
<p>
An exception to this rule is that fields may be initialized in constructors
without a mutex, since no other thread should be able to reference the memory
at that time.

</p>
<h4><a name="TOC-Recommended-commenting-convention"></a>Recommended commenting convention</h4>

There are two main dangers when using threads and mutexes: deadlocks and data races.
These can be avoided using some simple rules and adding
small comments to variable and procedure declarations.
You are strongly advised to use such comments; they may seem
tedious to write, but they help tremendously in avoiding errors.
The particular commenting conventions shown below are derived from the work of Nelson and Manasse.

<ul>
<li>
<p>Critical sections should almost always start and end in the same routine.  That is,
     if a routine acquires a lock, it should release it before it returns, and it should release
     no locks that it does not itself acquire.  This is normally achieved by writing
     <code>Acquire()</code> and <code>Release()</code> calls in pairs, or by using <code>AutoLock l(mu)</code>,
     which automatically releases <code>mu</code> when <code>l</code> goes out of scope.

</p>
</li>
<li>
<p> Every shared variable/field should have a comment
     indicating which mutex protects it:
     </p>
<pre>     int accesses_; // count of accesses (guarded by mu_)
     </pre>
     or a comment explaining why no mutex is needed:
     
<pre>     int table_size_; // no. of elements in table (readonly after init)
     </pre>
</li>
<li>
<p> Every mutex should have a comment indicating which variables and also any non-obvious 
     invariants it protects:
     </p>
<pre>     Lock mu_;       // protects accesses_, list_, count_
                      // invariant: count_ == number of elements in linked-list list_
     </pre>
     Think of the matching
     comments on variables and mutexes as analogous to
     matching types on procedure arguments and parameters; the redundancy can
     be very helpful to later maintainers of the code.
</li>
<li>
<p> Whenever a thread can hold two mutexes concurrently, either one
     (or both) of the mutexes should be commented with
     <code>acquired before</code> or <code>acquired after</code> to indicate
     which mutex must be acquired first:
     </p>
<pre>     Lock mu0_; // protects foo_ (acquired before mu1_)
     </pre>
     If the mutex acquisition order is not consistent, <a href="lock-and-condition-variable.html#deadlock">deadlock may result</a>.
</li>
<li>
<p> Each routine should have a comment indicating which mutexes must and must not be held on entry. 
     This allows implementors to edit routines without examining their call sites, and allows
     clients to use routines without reading their bodies.

</p>
</li>
<li>
<p> 
     Never hold locks when invoking a callback, as the callback may call into
     the module once more, leading to deadlock. (Violations of this rule
     should be extremely rare and conspicuously commented in the module's
     interface.)  Comments should indicate what threads can or cannot be used
     for callbacks:
     </p>
<pre>     // Call cb.Run() in "ms" milliseconds.
     // cb.Run() is called in a private thread; it will not be called
     // from the thread calling RunAfter(), even if ms==0.
     void RunAfter(Closure cb, int ms);
     </pre>
</li>
<li>
<p> In rare cases, it may be useful for a routine to acquire a lock and return without releasing
     it, or to release a lock (perhaps temporarily using
     <code>ConditionVariable::Wait</code>) that it did not acquire.  Such routines may surprise clients, and should
     be commented clearly in interfaces. Note that a routine that acquires
     a lock and returns without releasing it is practically a locking
     primitive and should be commented as such.

</p>
</li>
<li>
<p> Every condition variable should have a comment indicating when it is signalled:
     </p>
<pre>     ConditionVariable non_empty_;      // signalled when the queue becomes non-empty
     </pre>
</li>
<li>
<p> In some cases, exclusive access to data is ensured by referencing it only
    from one thread.  (See the section on <a href="lock-and-condition-variable.html#message">message passing</a>.)
    The thread can be thought of as playing the part of a mutex;
    you should name the thread and use the name in comments as if it were a lock.
    </p>
<pre>    int queue_length_;      // length of receive queue (under net_thread)
    ...
    // Process one packet from the queue. 
    // L &gt;= net_thread
    void ProcessPacket() {
      ...
    }
    </pre>
</li>
<li>
<p> In very rare cases, a variable may be protected by more than one mutex.
    This means that the variable may be read while holding any of the mutexes,
    but may be written only when all the mutexes are held.
    You should document it clearly in the comments.
    </p>
<pre>    int bytes_left_; // bytes remaining in queue (under mu_ and net_thread)
    </pre>
</li></ul>
If these conventions are followed it is straightforward to tell what locks are held 
at any point in a routine by reading the routine and its comments.  By reading the comments
on shared variables and mutexes, it is then possible to tell that all variable accesses
are correctly protected by a mutex, and that mutexes are acquired in the correct order.
<p>
Without such comments, working with mutexes is significantly harder.  We recommend
their use.

</p>
<h4><a name="TOC-Performance-hints"></a> Performance hints</h4>
<h5><a name="TOC-Critical-sections-should-not-be-too-long"></a>Critical sections should not be too long</h5>

Normally, you should hold mutexes for short periods (nanoseconds to microseconds) at a time,
and the mutexes should be free most of the time, often approaching 99%.
To achieve this, it's best to avoid doing slow operations such as I/O inside
critical sections---assuming it is not the purpose of the mutex to serialize the I/O, of course.

<p>
Another, more complex technique is to make the locking more <i>fine-grained</i>
by employing more locks, each protecting a subset of the data.   

</p>
<p>
Other transformations may help, such as breaking a critical section in two, or
arranging to perform long-running operations on state that is local to a
thread.  

</p>
<h5><a name="TOC-Lock-acquisitions-are-cheap-but-not-free"></a>Lock acquisitions are cheap but not free</h5>

A lock acquisition is generally more expensive than
a cached variable access, but less expensive than a cache miss.
If a mutex is acquired and released too often (say, more than a hundred
thousand times per second) the overhead of these operations themselves
may start to be significant in CPU profiles.
<p>
Frequent acquisition can be avoided by combining critical sections,
or by delaying operations on shared state by buffering them
in memory local to a single thread.  For example, <a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html">tcmalloc</a>
uses a per-thread cache of memory to avoid
locking overhead on every allocation.

</p>
<h3><a name="TOC-Pitfalls"></a>Pitfalls</h3>
<h4><a name="TOC-Deadlocks"></a>Deadlocks</h4>

A deadlock (sometimes called a <i>deadly embrace</i>) occurs when an
<i>activity</i> attempts to acquire a limited <i>resource</i> that has been
exhausted and cannot be replenished unless that activity makes progress.
<p>
When considering deadlocks involving only mutexes, each activity is typically
represented by a thread, and the resources are mutexes that are exhausted when
held, and replenished when released.  However, other possibilities exist:  In a
<a href="lock-and-condition-variable.html#message">message passing</a> environment,
an activity may be represented by a message, and a resource may be represented
by a bounded-length message queue or a bounded-size thread pool.  When both
mutexes and message passing are used, deadlocks may involve combinations of
these activities and resources. 
</p>
<p>
The simplest mutex-related deadlock is the <i>self-deadlock</i>:
</p>
<pre>  mu.Acquire();
  mu.Acquire();      // BUG: deadlock: thread already holds mu
</pre>
Deadlocks involving two resources, such as a mutex and a bounded-sized thread pool,
are easily generated too, but deadlocks involving three or more resources
are less common.   A two-mutex deadlock results when thread T0 attempts to
acquire M1 while holding M0 at the same time that thread T1 
attempts to acquire M0 while holding M1; each thread will wait indefinitely
for the other.

<h5><a name="TOC-Debugging-deadlocks"></a> Debugging deadlocks </h5>
Fortunately, deadlocks are among the easiest bugs to debug and avoid.
Debugging is typically easy because the address space stops exactly where 
the bug occurs.   A stack trace of the threads is usually all that is 
is required to see what the threads are waiting for and what resources
they hold.  (Deadlocks involving messages in queues can be harder to spot.)
<p>
</p>
<h5><a name="TOC-Avoiding-deadlocks"></a> Avoiding deadlocks </h5>

Deadlocks can be avoided by disallowing cycles in the resources'
exhaust-before graph; this can be done by imposing a partial order
on the graph.   If an activity can exhaust resource R0
and then attempt to use a resource R1 that may be exhausted, then 
we say that R0 <i>precedes</i> R1 (and R1 <i>follows</i> R0) in the exhaust-before graph.
To guarantee no deadlocks, it is sufficient to guarantee that if
R0 <i>precedes</i> R1, then R1 never <i>precedes</i> R0.  That is,
for all pairs of resources R0 and R1, either R0 and R1 are unordered
(neither <i>precedes</i> the other), or their ordering is unambiguous
(one <i>precedes</i> the other, but not vice versa).
<p>
Considering only mutexes, we can avoid deadlocks by ensuring
that the acquired-before graph is a partial order and is therefore free
of cycles.  In practice, we simply pick an order for any two mutexes
that can be held simultaneously by the same thread, and comment the code
with this choice. 
</p>
<p>
As described <a href="lock-and-condition-variable.html#comments">above</a>,
if a thread does <code>mu0.Acquire(); mu1.Acquire(); </code>
then we should comment the declarations of <code>mu0</code> and
<code>mu1</code> with either <code>acquired before</code> or
<code>acquired after</code> (or both).
Because we wish our code to be modular, our comments
should also indicate what locks a caller must or must not hold on entry to a routine.
Combined, these comments allow the programmer to know whether he is about to violate the locking order by
acquiring a mutex or calling a routine.
Experience shows that if this convention is followed, deadlocks are usually
both rare and easy to correct.
</p>
<p>
A particularly important rule of thumb for deadlock avoidance is
<a href="lock-and-condition-variable.html#callback">never hold a lock while invoking a callback</a>.
More generally, try to avoid holding locks for long periods, and across calls
to other levels of abstraction that you do not fully understand.  (That is,
you might hold a lock access an access to a hash table, but you should not
hold a lock across a call to a complex subsystem.)

</p>
<h4><a name="TOC-Races"></a> Races </h4>

Races occur in three main ways:
<ul>
<li>
<p> A shared variable is accessed without being protected consistently by a mutex.
     The reasons for the problems are discussed at length <a href="lock-and-condition-variable.html#why">below</a>.
     This error can be avoided with the conventions <a href="lock-and-condition-variable.html#comments">already described</a>;
     simply ensure that each shared variable is accessed only when its
     protecting mutex is known to be held. Such races can be detected
     automatically by <a href="http://code.google.com/p/data-race-test/wiki/ThreadSanitizer">ThreadSanitizer</a>
     as described <a href="lock-and-condition-variable.html#racedebug">below</a>.

</p>
</li>
<li>
<p> A critical section modifies protected state but does not
     <a href="lock-and-condition-variable.html#invariant_bug">preserve the monitor invariant</a>.  Such bugs
     are rare if invariants are commented correctly.

</p>
</li>
<li>
<p> A critical section reads protected state, which is then encoded in
     a temporary variable or the program counter.  Then the lock is released,
     then reacquired and the state from the previous critical section is used
     as though still valid:
     </p>
<pre>     string name_;  // guarded by mu_

     size_t NameLen() { AutoLock l(this-&gt;mu_); return this-&gt;name_.size(); }

     // Requires 0 &lt;= i &lt; this-&gt;name_.size()
     int CharFromName(size_t i) { AutoLock l(this-&gt;mu_); return this-&gt;name_[i]; }

     ...
     size_t len = this-&gt;NameLen();
     int x = 0;
     if (len &gt; 0) {
       // BUG: temporary len encodes protected state from a previous
       // critical section that is used inside another.
       // The length of name_ may have changed since len was assigned.
       x = this-&gt;CharFromName(len - 1);  
     }
     ...
     </pre>
     This is the most insidious form of race, and the best known way to avoid
     them is vigilance.  Fortunately, they are quite rare.
     There are algorithms that can detect such races using data flow analysis,
     but as yet none has been applied to C++.
</li></ul>
<h3><a name="TOC-Debugging"></a>Debugging</h3>
<code>Lock</code> and <code>ConditionVariable</code> have various features to aid debugging.

<h4><a name="TOC-Assertions"></a>Assertions</h4>
<ul>
<li>
<p>
<code>mu.AssertAcquired()</code>:  abort in debug mode if <code>mu</code>
is not held by the calling thread.
</p>
</li></ul>
<h4><a name="TOC-Race-detection"></a>Race detection</h4>
Race detection requires an external tool. One such tool is
<a href="http://code.google.com/p/data-race-test/wiki/ThreadSanitizer">ThreadSanitizer</a>, which is a dynamic race detector
based on the <a href="http://go/valgrind">Valgrind</a> binary translation
framework. See <a href="http://code.google.com/p/data-race-test/wiki/ThreadSanitizer">this page</a> for more details on how to use it with Chrome.

<h3><a name="TOC-Examples"></a>Examples</h3>

The following show simple implementations of reader-writer locks
and producer-consumer queues using condition variables.

<h4><a name="TOC-Reader-writer-lock"></a> Reader-writer lock </h4>

The example below could be improved in various ways at the cost of clarity.
In particular, they allow readers to starve writers.

<pre>class RWLock {
 public:
  RWAcquire() : lockers_(0), lock_free_(&amp;mu_) {}
  ~RWAcquire() {}
  void WriteAcquire() {        // acquire a write lock
    this-&gt;mu_.Acquire();
    while (this-&gt;lockers_ != 0) {
      this-&gt;lock_free_.Wait();
    }
    this-&gt;lockers_ = -1;
    this-&gt;mu_.Release();
  }
  void ReadAcquire() {         // acquire a read lock
    this-&gt;mu_.Acquire();
    while (this-&gt;lockers_ &lt; 0) {
      this-&gt;lock_free_.Wait();
    }
    this-&gt;lockers_++;
    this-&gt;mu_.Release();
  }
  void Release() {           // release lock (either mode)
    this-&gt;mu_.Acquire();
    this-&gt;lockers_ = (this-&gt;lockers_ == -1? 0 : this-&gt;lockers_ - 1);
    if (this-&gt;lockers_ == 0) {        // if lock became free, wake all waiters
      this-&gt;lock_free_.Broadcast();
    }
    this-&gt;mu_.Release();
  }
 private:
  Lock mu_;            // protects lockers_
  int lockers_;         // 0 =&gt; free, -1 =&gt; writer, +ve =&gt; reader count
  ConditionVariable lock_free_;   // signalled when lockers_ becomes 0
};
</pre>
<h4><a name="TOC-Producer-consumer-queue"></a>Producer-consumer queue</h4>
<pre>class PCQ {     // a bounded, blocking FIFO producer-consumer queue
 public:
  PCQ(int n) : max_count_(n), non_full_(&amp;mu_), non_empty_(&amp;mu_) {}
  ~PCQ() { CHECK_EQ(this-&gt;queue_.size(), 0); } // error if queue is not empty

  // waits until queue is not full, then adds value to its end
  void Add(void *value) {
    this-&gt;mu_.Acquire();
    while (this-&gt;queue_.size() == this-&gt;max_count_) {
      this-&gt;non_full_.Wait();
    }
    this-&gt;non_empty_.Signal(); // no need to Broadcast.
                               // (only one remover can consume this item)
                               // Could use:
                               // if (this-&gt;queue_.size() == 0) { this-&gt;non_empty_.Broadcast(); }
    this-&gt;queue_.push_back(value);
    this-&gt;mu_.Release();
  }

  // waits until this queue is non-empty, then removes and returns first value
  void *Remove() {
    this-&gt;mu_.Acquire();
    while (this-&gt;queue_.size() == 0) {
      this-&gt;non_empty_.Wait();
    }
    this-&gt;non_full_.Signal(); // no need to Broadcast.
                              // (only one adder can consume this gap)
                              // Could use:
                              // if (this-&gt;queue_.size() == this-&gt;max_count_) { this-&gt;non_full_.Broadcast(); }
    void *value = this-&gt;queue_.front();
    this-&gt;queue_.pop_front();
    this-&gt;mu_.Release();
    return value;
  }

 private:
  Lock mu_;             // protects *queue_
                         // protects invariant 0 &lt;= queue_.size() &lt;= max_count_
  deque&lt;void *&gt; queue_; // list of queued items
  const int max_count_;  // max number of items in *queue_ (readonly after init)
  
  ConditionVariable non_full_;    // signalled when queue becomes non-full
  ConditionVariable non_empty_;   // signalled when queue becomes non-empty
};

</pre>
<h2><a name="TOC-Why-are-mutexes-the-way-they-are-"></a>Why are mutexes the way they are?</h2>
<h3><a name="TOC-Why-use-a-mutex-when-accessing-shared-data-"></a>Why use a mutex when accessing shared data?</h3>

It is perilous to access data that another thread may be modifying concurrently.
Consider accesses to a C++ <code>string</code>.  A well-formed <code>string</code>
may have invariants, such as its length field indicating the true length of the
string it represents.  Such invariants may be temporarily broken by the <code>string</code>
implementation when an update occurs.  Clearly, one thread may not be allowed
to read a <code>string</code> that is being written by another, as it may not
observe a length consistent with the stored bytes.  If the string is accessed
only under a mutex <code>mu</code>, the <code>string</code>'s invariants
become <code>mu</code>'s monitor invariants, and each thread will see a well-formed
<code>string</code>.
<p>
It is tempting to assume that mutexes are unnecessary when there is no
obvious monitor invariant to protect.  Consider a variable or field with type <code>double</code>.
One might expect to be able to read and write this variable
from multiple threads without the protection of a mutex, but this is not safe:
</p>
<ul>
<li>
<p> Many machines, including the x86, do not guarantee
to access a <code>double</code> atomically.
(A stack-allocated double need not be naturally-aligned by the compiler, potentially leading to two 
memory operations for a single access.) 
Thus, there <em>is</em> an invariant we need to protect: that the <code>double</code> is well-formed.

</p>
</li>
<li>
<p>
On some machines seemingly
obvious data-dependency properties do not hold without the cross-thread synchronization
provided by a mutex; a thread might read a well-formed <code>double</code> but get a value
from an apparently earlier time.   This comment applies to all types, including
integers, pointers, and even <a href="lock-and-condition-variable.html#atomic">"atomic" types</a>
provided by the language or runtime.

</p>
</li>
<li>
<p>
A variable's concrete type may change as a program is maintained,
and this change may be hidden by a <code>typedef</code>.
</p>
</li></ul>
<p>
In short, data accessed by multiple threads should be protected
with a mutex.  To do otherwise is to court disaster.
</p>
<p>
Despite this advice, some programmers enjoy the intellectual challenge of using
lower-level primitives (<a href="lock-and-condition-variable.html#atomic">"atomic" types</a>, compare-and-swap, memory barrier) instead of mutexes.
There are many problems with such code:
</p>
<ul>
<li> it usually does not work.
</li>
<li> it is often no faster overall than using mutexes.
</li>
<li> it may rely on assumptions about the hardware or compiler, or both.
</li></ul>
However, the most important reason not to use such code is that it is complicated.
Even if the author understands it, the next maintainer of the code may not.
Worse, he may <i>think</i> he understands it.  
<p>
The best way to avoid locking is to avoid shared mutable state.
When shared mutable state is needed, use a mutex.
If you experience <a href="lock-and-condition-variable.html#perf">lock contention</a>, consider using
more mutexes, each
protecting less data (that is, make the locking finer-grained).
If you feel you must access a shared mutable variable
without a mutex, and have data that shows it is worth the maintenance expense of
doing so, ask an expert how to do it.



</p>
<h3><a name="TOC-Why-can-the-holder-of-a-Lock-not-reacquire-it-"></a>Why can the holder of a <code>Lock</code> not reacquire it?</h3>

Some mutex implementations, notably that of Java, and the Windows CRITICAL_SECTION are called <i>reentrant</i> or <i>recursive</i>.
They allow the holder of a mutex to reacquire the mutex without deadlocking by
maintaining an internal <i>acquisition count</i> and <i>holder</i> identity instead of the
<code>held</code> boolean.  The mutex is free when the count is zero.  
The acquisition count keeps track of the number of acquisitions performed
by the holder; the holder is required to release the mutex the same number of times
it acquired it to make the mutex free.
This bookkeeping allows a method of an object to call other methods
of the same object while holding the lock, even if those other methods acquire the lock.
We do not allow this apparently convenient usage in <code>Lock</code> not because
of the small additional cost of maintaining the counter, but because of two problems.
<p>
Recall that a mutex's primary purpose is to allow the programmer to maintain
monitor invariants, and that the programmer may assume a monitor invariant
just after acquiring the appropriate mutex.   Consider a Java method M0
that acquires a mutex <code>mu</code> protecting invariant <i>Inv</i>. 
The author of M0 is entitled to assume <i>Inv</i> at the moment he acquires <code>mu</code>.
Now consider another method M1 that acquires <code>mu</code>, invalidates <i>Inv</i> during an update, calls M0,
restores <i>Inv</i>, and releases <code>mu</code>.
M0 assumes <i>Inv</i>, but <i>Inv</i> is untrue when M0 is called, so M0 fails.
Remember that both M0 and M1 may have multiple implementations written by multiple authors
over years, and perhaps multiple implementations in the same program, due to inheritance.  
The source code of M0 may not be available to the author of M1, or
vice versa.  Without remarkably good discipline and documentation standards, the programmers
may not understand why M0 is not functioning correctly.
</p>
<p>
If a programmer attempted to do the same thing with a non-reentrant mutex such
as <code>Lock</code>, his code would instantly deadlock and a stack trace would show that a
thread is attempting to reacquire a lock it already holds.
Not only is the error discovered immediately, but the fix is usually trivial:
write a small method M0 that acquires <code>mu</code> and calls a private method M0',
which does the real work, assuming <i>Inv</i> but without
acquiring <code>mu</code>.  The specifications of M0 and M0' differ only in their locking
behaviour, so the programmer almost always documents this difference, often in
the names of M0 and M0'.  The presence of the additional method and the
corresponding name or comment provides an additional
reminder to the author of M1.   He realizes that
by calling M0' rather than M0, he has the burden of establishing
<i>Inv</i> before the call---it is not guaranteed automatically by the monitor invariant.
This solution is not a panacea, but disallowing reentrancy at least makes the error
apparent, rather than hiding it.
</p>
<p>
The second problem with reentrancy is associated with condition variables.  In
the example above, imagine that M0 waits on a condition variable and thus
effectively contains more than one critical section.
Normally M0 will work, but if called from M1 with <code>mu</code> held, it is
unclear what happens, and neither outcome is satisfactory.
If the wait() primitive decrements <code>mu</code>'s acquisition count by one,
<code>mu</code> does not become free, the condition never becomes
true, and the thread deadlocks.  If instead the
acquisition count is set to zero by <code>Wait()</code>, <code>mu</code> becomes free during
a critical section initiated by M1.  This is likely to 
cause M1 to malfunction silently.  In the non-reentrant case, M0 must be split into
M0 and M0' as before.  Since M0' waits on a condition variable, it now has an
interesting specification:  it temporarily releases a mutex that it did not
acquire.  This is unusual, and usually very dangerous,
so one might expect a comment to that effect.  This comment then tells the author of M1
that he must be especially careful if he calls M0'.

</p>
<h3><a name="TOC-Why-not-use-monitored-modules-or-automatically-locked-objects-locking-pointers-lock-free-data-structures-...-"></a>Why not use monitored modules? (or automatically locked objects, locking pointers, lock-free data structures, ...)</h3>

It seems attractive to automate the acquisition and release of mutexes by
declaring somehow that a mutex will be acquired on entry to a module and
released on exit, as in a Hoare monitor.  This can be used for trivial cases, but
even quite common examples require more complex locking. 

<p>
Consider a table
<code>*t</code> mapping strings to integer counts.  The table might have
methods <code>insert()</code>, <code>lookup()</code>, <code>remove()</code>.
If the table provides its own synchronization, perhaps inserted automatically in each
method by some mechanism, we eliminate data races within the table itself,
but this does not help the client.  Consider this code, which increments the count for
"foo" in the table <code>*t</code>:
</p>
<pre>  int *v = t-&gt;lookup("foo");   // safe because *t is a monitor
  if (v != 0) {
    (*v)++;               // BUG: data race: unlocked increment
  } else {
    t-&gt;insert("foo", 1);  // safe because *t is a monitor
  }
</pre>
If the client does not use his own mutex, counts may be missed.
If he does, the synchronization inside <code>*t</code> is redundant.
Thus, monitored modules are rarely helpful.

<p>
The implementors of SGI STL made the
<a href="http://www.sgi.com/tech/stl/thread_safety.html">same observation</a>.

</p>
<p>
A further problem is that the designers of automatic locking mechanisms often
desire to reduce the amount of typing needed to implement a monitor, rather
than to improve the readability and maintainability of the code.
All too often, these two desires are in conflict; some code is 
<a href="lock-and-condition-variable.html#autolock">more readable</a>
if one can tell when a lock is released.


</p>
<h3><a name="TOC-Alternatives-to-mutexes"></a>Alternatives to mutexes</h3>

There are a number of ways to handle concurrency, and ways to avoid it
altogether.  Of the various possible models, only two permit high-performance
implementations that can use multiple CPUs and sharing of resources, and still
allow large programs to be built from smaller components while maintaining
abstraction boundaries.  These models are "threads + mutexes +
condition-variables", and "threads + message-passing".  These
two can be used together, and often are.

<h4><a name="TOC-Message-passing"></a>Message passing</h4>

One can associate data with threads, so that each thread <i>owns</i> some variables
and data structures; a variable is accessed only by its owning thread.
Other threads wishing to access
the data then communicate with the owning thread via <i>message
passing</i>, such as Chrome's <code>TaskRunner</code>.
<p>
This style is a dual of the mutex-based style (see Lauer and Needham's
oft-cited paper on the subject):  A message-send corresponds to
acquiring a mutex; running in a critical section corresponds to executing code
within the owning thread; and receiving a reply corresponds to releasing the
mutex.  Thus, the most obvious difference between the approaches is that 
in message-passing all the code that manipulates a particular data item is
brought together into one thread,
while with mutexes the data accesses can be interleaved with other code.
</p>
<p>
Message passing and mutexes can be intermixed; often one is preferred
either because the author is comfortable with the style, or because
one leads to a clearer module than the other.
The message-passing model tends to work well when there is a
natural resource that already serializes accesses (such as an I/O device),
a linear state machine best expressed as a single routine,
or when critical sections are long.
Mutexes work well when critical sections are short and may be
invoked in many places, or when reader-writer locks can be used effectively.
In Chrome code, message passing is much more common
(via <code>TaskRunner</code> and <code>PostTask</code>) and low-level
primitives like locks and condition variables are used only when
necessary.
</p>
<p>
Both models allow high-throughput implementations,
and both can suffer from both races and deadlocks.  Deadlocks can often be
eliminated in the message-passing model by using unbounded queues and/or threadpools.

</p>
<h4><a name="TOC-Atomic-types-and-atomic-operations"></a>Atomic types and atomic operations</h4>

Many runtimes and languages (including C++11)
provide atomic operations, such as compare-and-swap, and "atomic" types
that can be read and written atomically.   Atomic operations and types
are much harder to use than one might first think,
and they should not be used in normal code.
Unfortunately, programmers are attracted to them for various reasons:
<ul>
<li>
<p> Programmers enjoy the intellectual puzzle of using these operations.
     This leads to clever, but ill-advised, and often broken code.
     </p>
<p>
     Algorithms involving atomic operations are extremely subtle.
     For example, a general-purpose, efficient, lock-free,
     singly-linked list algorithm took
     significant research to discover, and requires care to implement.  Almost
     all programmers make mistakes when they attempt direct use of atomic
     operations.  Even when they don't make mistakes, the resulting code is
     hard for others to maintain. Both CPUs and compilers can rearrange reads and writes in ways that lead to subtle race conditions. The simple-sounding pattern of <a href="http://en.wikipedia.org/wiki/Double-checked_locking" target="_blank">double-checked locking</a> is actually extremely subtle and is usually implemented incorrectly.</p>
</li>
<li>
<p> Programmers assume that locking is expensive, and that using atomic
     operations will be more efficient.  But in reality, acquiring and
     releasing a lock is cheaper than a cache miss; attention to cache behaviour
     is usually a more fruitful way to improve performance.   Furthermore,
     lock-free data structures are often more expensive than using locks. 
     This is because a lock allows arbitrary changes to be made to a complex
     data structure; if the same changes must be made without a lock, the
     result is likely to take more atomic read-modify-write instructions, not
     fewer.

</p>
</li>
<li>
<p> People wish to avoid lock contention when concurrency is high.
     This is best solved by partitioning locked data structures to avoid lock
     contention.  For example, it is easier, more efficient, and
     <a href="lock-and-condition-variable.html#monitors">more useful</a> to build a
     high-concurrency hash table from many normal hash tables, each with its own
     lock, than to build one lock-free hash table using atomic operations.
</p>
</li></ul>

Atomic operations should be used in only a handful of low-level data
structures, written by a few experts, and then reviewed and tested thoroughly.
Unfortunately, many attempt to write lock-free code, and almost always this is
a mistake.  Please do not fall into this trap:  do <i>not</i> use atomic
operations or types---if you do, you will make mistakes, and you will cost the
company time and money.


<h4><a name="TOC-A-single-thread"></a>A single thread</h4>

A process that uses only a single thread requires no mutexes, and
this is often the best approach for simple programs that do not
require high performance or that are inherently sequential.
However, it is usually not the best choice for large programs,
or when high performance is required.
<ul>
<li>
<p> A single-threaded application can use 
only one CPU, which typically makes it far slower than other options, even when
the overheads of locking are taken into account. 
If the application is simple
enough, one may be able to run multiple copies of the same program
on each machine, but this introduces two inefficiencies:  
cross-address-space context switches are more expensive than thread context
switches because threads share TLB entries while address spaces do not; and
the address space separation precludes sharing some resources (caches, ports, etc.).

</p>
</li>
<li>
<p> Some programs, such as network servers, exhibit natural concurrency:
they must deal with many concurrent client requests, so some mechanism is needed to
allow this.
</p>
</li></ul>
<h5><a name="TOC-The-fallacy-of-thread-context-switch-cost"></a>The fallacy of thread context-switch cost</h5>

Some try to argue that it is significantly cheaper to multiplex a single thread
than to use multiple threads because a single thread requires no thread context switches. 
Such an argument stems from confusion about what constitutes a "context
switch" and what contributes to its cost.   A context switch is simply the act of multiplexing
the processor between multiple activities; its dominant costs  are similar
regardless of whether this is done in kernel-mode or in user-mode:
<ol>
<li>
<p> When a program switches to a new activity, it incurs cache and TLB misses by touching the
     data and instructions associated with a new activity.  This cost is the most important,
     and is essentially the same 
     regardless of whether the new activity
     takes place in a different thread or in the same thread.  The cost occurs
     not only when a multithreaded program performs a thread context switch, but also
     when an <a href="lock-and-condition-variable.html#event">event
     driven</a> program processes a new event, or when a
     <a href="lock-and-condition-variable.html#coop">co-operative multithreaded</a> program switches context in
     user-space.  Multithreaded programs rarely context switch due to time-slicing
     because time-slices are large.
</p>
</li>
<li>
<p> The cost of user-kernel mode switches is sometimes counted as part of
     the context-switch cost between threads.  However, 
     multithreaded programs usually context switch when
     they have <i>already</i> entered the kernel for other reasons---typically, 
     via some system call or to service an interrupt.
     A single-threaded program incurs these same mode switches,
     and thus they are common to all models.  One might expect
     mutex and condition variable calls to add to the number of system calls,
     but this effect is modest because
     uncontended mutexes induce no system calls, while contended mutexes
     and condition-variable operations should be relatively rare.
</p>
</li>
<li>
<p> Context switches between address spaces are more expensive because
     TLB entries must be replaced.
</p>
</li>
</ol>
To summarize, if a single address space is used, the costs of switching between activities
are nearly independent of the number of threads used within that address space;
the technique that leads to slowest execution is to run multiple copies of a
single-threaded program.


<h5><a name="TOC-The-event-driven-style"></a>The event-driven style</h5>

To handle concurrent activities
in a single thread, some programmers adopt a style variously known as <i>event-driven</i>,
<i>state-machine</i> or <i>continuation-passing</i>:  One can decompose
the actions for a given request into a graph of <i>handler</i> routines that never
block for I/O internally, but rather specify which handlers should be invoked
when pending I/O requests complete.  This approach can be made to work and may even be
straightforward in simple programs, but it has bad effects on
readability, modularity, and abstraction, as well as using only one CPU.

To see the problems with the event-driven style,
consider the code
<pre>  ...
  for (int i = 0; i != 10; i++) { foo(i); }
  ...
</pre>
Now imagine that the third-party library routine <code>foo()</code> is 
modified at some future time  to improve its functionality or average performance.
Imagine that a side-effect of this improvement is that occasionally <code>foo()</code> must perform
some blocking I/O that should not be performed within a handler.  Neither the
author of the for-loop nor the author of the new implementation of
<code>foo()</code> has done anything unusual, and yet the program may show
poor throughput or even deadlock in an event-driven environment.
Even subtler changes can have undesirable effects.
Imagine that <code>foo()</code> includes a call to <code>fprintf()</code>;
if one day the output stream is redirected to a device with high-throughput but
high-latency, the program's throughput will drop precipitously because
<code>foo()</code>'s latency cannot be hidden in the event-driven model without rewriting
both <code>fprintf()</code> and <code>foo()</code>.
<p>
We can fix the performance problem if we change <code>foo()</code>'s signature
to include a continuation to be called when <code>foo()</code> completes.
However, this is not a local change:  the loop must be restructured so
that the loop variable is encoded in the continuation state.  Worse, <i>every</i>
use of <code>foo()</code> must be similarly modified not only to handle the new signature, but 
to break the calling procedure into two---the prefix before the call to <code>foo()</code>,
and the continuation.   Thus, a <i>local</i> change in
<code>foo()</code> has affected an arbitrary number of modules in a significant
way: the event-driven style does not preserve modularity.
</p>
<p>
Notice how this differs from the multi-threaded case.  Just as the event-driven style
style requires that <code>foo()</code> be non-blocking, the multithreaded style
requires
that <code>foo()</code> be thread-safe.
However, this constraint is easier to live with.  First,
most libraries are thread-safe
either naturally or by design, while few are designed for use in event-driven systems.
(For example, <code>fprintf()</code> is thread safe, but provides no callback
mechanism.)  Second, if <code>foo()</code> were not thread safe,
calls to it 
can be made safe <i>either</i> by a change to <code>foo()</code> <i>or</i> by wrapping
<code>foo()</code> with a new routine <code>foo()</code> that acquires a lock before
calling the old <code>foo()</code>.
Either change is local, and does not affect other aspects of the
interface, so modularity is preserved. 
</p>
<p>
The problem with the event-driven style is worse for routines like
<code>printf()</code> whose signatures cannot be changed lightly.
Even more worryingly, some I/O methods cannot be made efficient in a
single-threaded event-driven system <i>even with arbitrary restructuring of the
entire program</i>.  For example,  while one can with effort write a
continuation-passing equivalent of <code>printf()</code>, memory-mapped I/O and
programmed I/O have no such equivalent.
</p>
<p>
A further problem with the event-driven style is that the resulting code
becomes quite difficult to understand, maintain, and debug.  This is primarily
because it is harder to tell from reading the code which routine caused the
current one to be called, and which routine will be called next.  Standard
debugging and performance tools become less effective too, as they rarely have
support for tracing through continuations, and continuation mechanisms rarely
maintain call history.  In contrast, non-event-driven programs maintain much of
their state and history conveniently on the thread stacks; debugging tools can
reveal a great deal simply by displaying stack traces.

</p>
<h5><a name="TOC-Co-operative-multithreading"></a>Co-operative multithreading</h5>
An alternative style called <i>co-operative multithreading</i>
allows the programmer to use multiple threads on a single CPU.
The scheduler guarantees that no two threads can run concurrently, and guarantees never to 
pre-empt a thread that has not blocked.  In theory, this allows
mutexes to be omitted: the code <code>a++; b--;</code> will
always execute atomically.  Unfortunately, reliance on this property makes the code
more fragile.  For example, because any I/O may block,
<code>a++; printf("bar\n"); b--;</code> probably does not execute atomically,
and <code>a++; foo(); b--;</code> may or may not execute atomically,
depending on the implementation of <code>foo()</code>.
Thus, co-operative multithreading without explicit synchronization can lead to
code in which a bug may be introduced to one module by adding a debug
printf-statement in another module.  If explicit synchronization is used,
the technique becomes equivalent to the straightforward use of threads.

<p>
For these reasons, unless a program is quite simple it usually pays in both
performance and maintainability to use multiple threads, and to protect shared
variables explicitly with mutexes or to communicate between threads with messages.

</p>
<h3><a name="TOC-Why-is-cv.Wait-always-in-a-while-loop-"></a>Why is <code>cv.Wait()</code> always in a while-loop?</h3>

Hoare's original condition variables did not require the while-loop,
but modern versions require it for somewhat subtle reasons:
<ul>
<li>
<p> The presence of the while-loop allows one to tell by <i>local</i>
     inspection that the condition is true when the loop exits.  Hoare's original
     precise semantics required inspection of all code that could potentially call
     <code>Signal()</code>, which made some errors rather harder to debug.
 
</p>
</li>
<li>
<p> The while-loop allows clients to do spurious wakeups, which gives the programmer
     the opportunity to trade performance for ease of programming.  Suppose he arranges
     for threads <i>always</i> to signal the condition variable when they
     modify protected state, rather than only when they make a specific
     condition true.  This allows modularity between waiters and wakers:  the
     wakers don't need to know what conditions wakers are waiting for, and each
     waiter can wait for a different condition without affecting the code of
     the wakers.

</p>
</li>
<li>
<p> The while-loop allows the condition variable implementation more freedom
     to schedule woken threads in any order.  Consider a thread T0 that wakes
     thread T1 that was waiting for condition C.  If the runtime semantics
     guarantee that T1 will enter the critical section next, T1 can assume C.
     But context switches have overhead, so it is usually more efficient
     merely to add T1 to the run queue while continuing to run T0 and perhaps other threads,
     which may then enter the critical section before T1.  If any of those threads
     falsifies C, T1 must not assume C on entering the critical section; scheduling
     has made it appear that it has received a spurious wakeup.  The
     while-loop ensures that T1 tests C, and continues only if C is really true.
     Thus, the while-loop effectively allows more freedom in choosing an
     efficient scheduling discipline.  

</p>
</li>
<li>
<p> Timed waits become less error-prone.  A timed wait may cause a thread to
     wake before its condition C is true.  Suppose the programmer forgets
     to test for a timeout.  If he is forced to use a while-loop, his thread
     will go to sleep again and his program will probably deadlock, allowing
     easy detection of the bug.  Without the while-loop, the thread would 
     falsely assume C, and cause arbitrarily bad behaviour.

</p>
</li></ul>
<h3><a name="TOC-Why-must-the-condition-used-with-cv.Wait-be-a-function-of-state-protected-by-the-mutex-"></a>Why must the condition used with <code>cv.Wait()</code> be a function of state protected by the mutex?</h3>

Consider a thread W waiting for a condition <code>cond_expr</code> to become
true:
<pre>  mu.Acquire();
  while (!cond_expr) {
    cv.Wait();  // mu was passed to cv's constructor
  }
  // cond_expr now holds
  ...
  mu.Release();
</pre>
If <code>cond_expr</code> is not a function of state protected by
<code>mu</code>, two bad things can happen:
<ol>
<li>
<p> Suppose that thread W finds <code>cond_expr</code> false, and is about to
     call <code>cv.Wait()</code>.  If the state associated with
     <code>cond_expr</code> is not protected by <code>mu</code>, another thread
     can make <code>cond_expr</code> true and call <code>cv.Signal()</code>
     before W calls <code>cv.Wait()</code>.  This means that W may block
     indefinitely in <code>Wait()</code>, even though <code>cond_expr</code> is
     true (only a thread currently in <code>Wait()</code> is woken by a call to
     <code>Signal()</code>).
</p>
</li>
<li>
<p> Suppose that thread W finds <code>cond_expr</code> true, and is about to
     execute the code labelled "cond_expr now holds".  If the state
     associated with <code>cond_expr</code> is not protected by
     <code>mu</code>, another thread can make <code>cond_expr</code> false
     before W runs the rest of the code, so W cannot assume
     <code>cond_expr</code>.  This negates the purpose of the condition
     variable, which was to give W a guarantee about <code>cond_expr</code>.
</p>
</li>
</ol>
<h3><a name="TOC-Why-put-Signal-inside-the-critical-section-"></a>Why put <code>Signal()</code> inside the critical section?</h3>

In most cases, it is correct to put <code>Signal()</code> 
after the critical section, but in Chrome code it is <i>always</i>
both safe and efficient to put it inside the critical section. (TODO: verify this)

<p>
Some texts recommend putting <code>Signal()</code> after the critical
section because this makes it more likely that the mutex is free
when a thread attempts to reacquire it on return from <code>Wait()</code>.
If the <code>Signal()</code> were inside the critical section,
a naive implementation might wake the thread which could then
block once more on the mutex held by the very thread that woke it.
</p>
<p>
Chrome's condition variables (and most reasonable implementations)
detect this case, and delay waking the waiting thread until the mutex
is free. (TODO: verify this) Hence, there is no performance penalty
for calling <code>Signal()</code> inside the critical section.
</p>
<p>
In rare cases, it is incorrect to call <code>Signal()</code> after
the critical section, so we recommend always using it inside the
critical section.  The following code can attempt to access the condition
variable after it has been deleted, but could be safe if <code>Signal()</code>
were called inside the critical section.
</p>
<pre>  struct Foo { Lock mu; ConditionVariable cv; bool del; ... };
  ...
  void Thread1(Foo *foo) {
    foo-&gt;mu.Acquire();
    while (!foo-&gt;del) {
      foo-&gt;cv.Wait();
    }
    foo-&gt;mu.Release();
    delete foo;
  }
  ...
  void Thread2(Foo *foo) {
    foo-&gt;mu.Acquire();
    foo-&gt;del = true;
                          // Signal() should be called here
    foo-&gt;mu.Release();
    foo-&gt;cv.Signal();     // BUG: foo may have been deleted
  }
</pre>
<h3><a name="TOC-Why-should-implementors-of-mutexes-pay-attention-to-mutex-performance-under-contention-"></a>Why should implementors of mutexes pay attention to mutex performance under contention?</h3>

Clients should avoid lock contention, because contention necessarily implies
less parallelism; some threads are blocked while another executes the critical section.
Because clients must avoid contention, some implementors of mutexes pay less
attention to the performance of mutexes under contention.
However, contention is sometimes encountered despite clients' best efforts.
For example:
<ul>
<li>
<p>
    A network server may become overloaded or see a changed pattern of use,
    causing a mutex to be used more than it normally would.
</p>
</li>
<li>
<p>
    A program may be run on an upgraded machine with more CPUs,
    causing contention on a mutex that was previously lightly loaded.
</p>
</li>
<li>
<p>
    Software developers encourage abstraction between parts of our programs, so
    the authors and clients of modules may have different expectations of how
    the module will be used.  In particular, a client may cause contention on a
    mutex that he is unaware of.
</p>
</li></ul>

While it is important for clients to fix contention to avoid loss of parallelism,
that loss of parallelism should be their main consideration.
The performance of the mutex itself should not degrade precipitously, even when
heavily contended.   That is: an overloaded server should recover from overload
if the load drops once more; a machine with more CPUs should run no slower than
a machine with fewer CPUs; and calling a module more often should not reduce
the amount of work that gets done, even if it doesn't increase it.
<p>
Ideally, a critical section should provide approximately the same rate
of progress to many contending threads as it can to a single thread.
Mutex implementations can approximate this ideal by not providing
fairness, and by preventing multiple threads that have already blocked from
simultaneously competing for the lock.


</p>
<h3><a name="TOC-Does-every-Lock-operation-imply-a-memory-barrier-"></a>Does every Lock operation imply a memory barrier?</h3>

Programmers should not use <code>Lock</code> operations as a means for inserting arbitrary
memory barriers into their code.  (Or for exerting control over when
threads run.)  <code>Lock</code> operations imply only ordering
necessary for the protection of monitor invariants.  In
particular, the intent is:
<p>
<i>If</i> threads T<sub>0</sub> and T<sub>1</sub> execute the following code,
where some location is modified by one of <code>T<sub>0</sub>_Inside()</code> and
<code>T<sub>1</sub>_Inside()</code> and read or written by the other:
</p>
<pre>        // thread T<sub>0</sub>            // thread T<sub>1</sub>
        T<sub>0</sub>_Before();            T<sub>1</sub>_Before();
        mu.Acquire();           mu.Acquire();
        T<sub>0</sub>_Inside();            T<sub>1</sub>_Inside();
        mu.Release();           mu.Release();
        T<sub>0</sub>_After();             T<sub>1</sub>_After();
</pre>
<i>then</i> the memory operations in <code>T<sub>x</sub>_Before()</code> and
<code>T<sub>x</sub>_Inside()</code> all precede the memory operations in
<code>T<sub>y</sub>_Inside()</code> and <code>T<sub>y</sub>_After()</code>
either for <code>x=0, y=1</code> or for <code>x=1, y=0</code>.

<p>
If the predicate does not hold, no memory ordering should be assumed from the
<code>Lock</code> operations.  This surprises programmers who expect the simplest possible
implementation, with no optimizations.  Unfortunately, this expectation
is reinforced by some API standards.

</p>
<p>
We discourage such assumptions because they make 
various transformations more difficult. Examples include:
</p>
<ul>
<li> Removal of critical sections that are redundant with others.
</li>
<li> Removal of locks used by only one thread, or that protect no data.
</li>
<li> Coalescing and splitting of locks and critical sections.
</li>
<li> Conversion of exclusive locks to shared locks.
</li>
<li> Replacing locks with transactional memory.
</li></ul>
Some lock implementations already apply some of these transformations,
and are more efficient as a result.  Therefore,
<code>Lock</code> reserves the right to use such transformations when safe,
even if that means removing memory barriers.</div></td></tr></tbody></table>
</div> 
</div> 
<div id="sites-canvas-bottom-panel">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-subpages"> </div>
<div id="sites-attachments-container">
</div>
<a xmlns="http://www.w3.org/1999/xhtml" name="page-comments"></a>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-comments"><div class="sites-comment-docos-wrapper"><div class="sites-comment-docos"><div class="sites-comment-docos-background"></div><div class="sites-comment-docos-header"><div class="sites-comment-docos-header-title">Comments</div></div><div id="sites-comment-docos-pane" class="sites-comment-docos-pane"></div></div></div></div>
</div>
</div> 
</td> 
</tr>
</table> 
</div> 
</div> 
<div id="sites-chrome-footer-wrapper">
<div id="sites-chrome-footer-wrapper-inside">
<div id="sites-chrome-footer">
</div>
</div>
</div>
</div> 
</div> 
<div id="sites-chrome-adminfooter-container">
<div xmlns="http://www.w3.org/1999/xhtml" class="sites-adminfooter" role="navigation"><p><a class="sites-system-link" href="https://www.google.com/a/UniversalLogin?service=jotspot&amp;continue=https://sites.google.com/a/chromium.org/dev/developers/lock-and-condition-variable">Sign in</a><span aria-hidden="true">|</span><a class="sites-system-link" href="../system/app/pages/recentChanges.html">Recent Site Activity</a><span aria-hidden="true">|</span><a class="sites-system-link" href="../system/app/pages/reportAbuse.html" target="_blank">Report Abuse</a><span aria-hidden="true">|</span><a class="sites-system-link" href="javascript:;" onclick="window.open(webspace.printUrl)">Print Page</a><span aria-hidden="true">|</span><span class="sites-system-link">Powered By</span> <b class="powered-by"><a href="http://sites.google.com">Google Sites</a></b></p></div>
</div>
</div> 
</div> 
<div id="sites-chrome-onebar-footer">
</div>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('sjl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" src="https://ssl.gstatic.com/sites/p/56e332/system/js/jot_min_view__en.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('jl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml">
      
          sites.core.Analytics.createTracker();
          sites.core.Analytics.trackPageview();
        
    </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
                    sites.Searchbox.initialize(
                        'sites-searchbox-search-button',
                        {"object":[]}['object'],
                        'search-site',
                        {"label":"Configure search options...","url":"/system/app/pages/admin/settings"});
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
      gsites.HoverPopupMenu.createSiteDropdownMenus('sites-header-nav-dropdown', false);
    </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("7648876402527094", "Navigation", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_7648876402527094');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("14720868319272995", "Quick links", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_14720868319272995');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("19690813310444355", "Other sites", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_19690813310444355');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
              new sites.CommentPane('//docs.google.com/comments/d/AAHRpnXvrAwjAfmld0ObrebBiGRq9nWbjRuNxNjkLLoIuzTQ_YwZoZyaC-B13faKrBvxOzREA_uNwtYN4WLBNkbmvzF-ia9_Cg4sPAc64THJADi5Yp65LMuXPkCXTSj5fXColdu0GJSIk/api/js?anon=true',
                  false, false);
            </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
  setTimeout(function() {
    var fingerprint = gsites.date.TimeZone.getFingerprint([]);
    gsites.Xhr.send('https://www.chromium.org/_/tz', null, null, 'GET', null, null, { afjstz: fingerprint });
  }, 500);
</script>
<script xmlns="http://www.w3.org/1999/xhtml">
                    window.onload = function() {
                      if (false) {
                        JOT_setMobilePreview();
                      }
                      var loadTimer = window.jstiming.load;
                      loadTimer.tick("ol");
                      loadTimer["name"] = "load," + webspace.page.type + ",user_page";
                      window.jstiming.report(loadTimer, {}, 'https://gg.google.com/csi');
                    }
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
        JOT_insertAnalyticsCode(false,
            false);
      </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    var maestroRunner = new gsites.pages.view.SitesMaestroRunner(
        webspace, "en");
    maestroRunner.initListeners();
    maestroRunner.installEditRender();
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
  //<![CDATA[
    // Decorate any fastUI buttons on the page with a class of 'goog-button'.
    if (webspace.user.hasWriteAccess) {
      JOT_decorateButtons();
    }

    // Fires delayed events.
    (function() {
      JOT_fullyLoaded = true;
      var delayedEvents = JOT_delayedEvents;
      for (var x = 0; x < delayedEvents.length; x++) {
        var event = delayedEvents[x];
        JOT_postEvent(event.eventName, event.eventSrc, event.payload);
      }
      JOT_delayedEvents = null;
      JOT_postEvent('pageLoaded');
    })();
  //]]>
</script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    JOT_postEvent('decorateGvizCharts');
  </script>
<script type="text/javascript">
          JOT_setupPostRenderingManager();
        </script>
<script type="text/javascript">
          JOT_postEvent('renderPlus', null, 'sites-chrome-main');
        </script>
<div id="server-timer-div" style="display:none"> </div>
<script type="text/javascript">
          window.jstiming.load.tick('render');
          JOT_postEvent('usercontentrendered', this);
        </script>
</body>
</html>
