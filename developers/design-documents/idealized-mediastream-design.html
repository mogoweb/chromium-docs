<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://schema.org/WebPage">
<head>
<meta http-equiv="X-UA-Compatible" content="chrome=1" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var e="wtsrt_",g="tbsd_",h="tbnd_",k="start",l="_wtsrt",m="_tbnd",n="CSI/";(function(){function f(a){this.t={};this.tick=function(a,c,b){this.t[a]=[void 0!=b?b:(new Date).getTime(),c];if(void 0==b)try{window.console.timeStamp(n+a)}catch(d){}};this.tick(k,null,a)}var a;window.performance&&(a=window.performance.timing);var p=a?new f(a.responseStart):new f;window.jstiming={Timer:f,load:p};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick(l,void 0,c),b.tick(e,l,d),b.tick(g,e))}try{a=null,
window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick(m,void 0,window.chrome.csi().startE),b.tick(h,m,c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick(m,void 0,window.external.startE),b.tick(h,m,c))),a&&(window.jstiming.pt=a)}catch(q){}})(); })()
</script>
<link rel="shortcut icon" href="../../_/rsrc/1354323194313/favicon.ico" type="image/x-icon" />
<link rel="apple-touch-icon" href="https://ssl.gstatic.com/sites/p/56e332/system/app/images/apple-touch-icon.png" type="image/png" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var d="",g="__duration__",h="function";function k(c){return document.getElementById(c)}window.byId=k;function l(c){return c.replace(/^\s+|\s+$/g,d)}window.trim=l;var m=[],n=0;window.JOT_addListener=function(c,a,b){var e=new String(n++);c={eventName:c,handler:a,compId:b,key:e};m.push(c);return e};window.JOT_removeListenerByKey=function(c){for(var a=0;a<m.length;a++)if(m[a].key==c){m.splice(a,1);break}};
window.JOT_removeAllListenersForName=function(c){for(var a=0;a<m.length;a++)m[a].eventName==c&&m.splice(a,1)};window.JOT_postEvent=function(c,a,b){var e={eventName:c,eventSrc:a||{},payload:b||{}};if(window.JOT_fullyLoaded)for(a=m.length,b=0;b<a&&b<m.length;b++){var f=m[b];f&&f.eventName==c&&(e.listenerCompId=f.compId||d,(f=typeof f.handler==h?f.handler:window[f.handler])&&f(e))}else window.JOT_delayedEvents.push({eventName:c,eventSrc:a,payload:b})};window.JOT_delayedEvents=[];
window.JOT_fullyLoaded=!1;window.JOT_formatRelativeToNow=function(c,a){var b=((new Date).getTime()-c)/6E4;if(1440<=b||0>b)return null;var e=0;60<=b&&(b/=60,e=2);2<=b&&e++;return a?window.JOT_siteRelTimeStrs[e].replace(g,Math.floor(b)):window.JOT_userRelTimeStrs[e].replace(g,Math.floor(b))}; })()
</script>
<script>

  

  var breadcrumbs = [{"path":"/developers","deleted":false,"title":"For Developers","dir":"ltr"},{"path":"/developers/design-documents","deleted":false,"title":"Design Documents","dir":"ltr"},{"path":"/developers/design-documents/idealized-mediastream-design","deleted":false,"title":"Idealized MediaStream Design","dir":"ltr"}];
  var JOT_clearDotPath = 'https://ssl.gstatic.com/sites/p/56e332/system/app/images/cleardot.gif';

  
  var JOT_userRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

  
  

  

  var webspace = {"enableAnalytics":true,"pageSharingId":"jotspot_page","enableUniversalAnalytics":false,"sharingPolicy":"OPENED_WITH_INDICATOR","siteTitle":"The Chromium Projects","isStartPageEnabled":true,"adsensePublisherId":null,"features":{"languageSelectDefaultTextSetToDefault":true,"validateClientGvizDataSourceUrls":true,"moreMobileStyleImprovements":true,"newInsertMenuIcons":true,"accessibleSortingButtons":true,"domainAnalyticsInGAOnly":true,"noCaptcha":true,"fileCabinetScreenReaderFix":true,"updatedTosAndPrivacyLinks":null,"pageDrafts":false,"mobileOrientationFix":true,"plusBadge":false,"pdfEmbedSupport":false,"jsClickFix":true},"isPublic":true,"isConsumer":false,"serverFlags":{"cajaBaseUrl":"//www.gstatic.com/caja","cajaDebugMode":false},"onepickBaseUrl":"https://docs.google.com","domainAnalyticsAccountId":"","plusPageId":"","signInUrl":"https://www.google.com/a/SelectSession?continue\u003dhttps://sites.google.com/a/chromium.org/dev/developers/design-documents/idealized-mediastream-design\u0026service\u003djotspot","analyticsAccountId":"UA-5484340-1","scottyUrl":"/_/upload","homePath":"/","siteNoticeUrlEnabled":null,"plusPageUrl":"","adsensePromoClickedOrSiteIneligible":true,"csiReportUri":"https://gg.google.com/csi","sharingId":"jotspot","termsUrl":"//www.google.com/intl/en/policies/terms/","gvizVersion":1,"editorResources":{"sitelayout":["https://ssl.gstatic.com/sites/p/56e332/system/app/css/sitelayouteditor.css"],"text":["https://ssl.gstatic.com/sites/p/56e332/system/js/codemirror.js","https://ssl.gstatic.com/sites/p/56e332/system/app/css/codemirror_css.css","https://ssl.gstatic.com/sites/p/56e332/system/js/trog_edit__en.js","https://ssl.gstatic.com/sites/p/56e332/system/app/css/trogedit.css","/_/rsrc/1441580320000/system/app/css/editor.css","https://ssl.gstatic.com/sites/p/56e332/system/app/css/codeeditor.css","/_/rsrc/1441580320000/system/app/css/camelot/editor-jfk-wlb.css"]},"sharingUrlPrefix":"/_/sharing","isAdsenseEnabled":true,"domain":"chromium.org","baseUri":"","name":"dev","siteTemplateId":false,"siteNoticeRevision":null,"siteNoticeUrlAddress":null,"siteNoticeMessage":null,"page":{"isRtlLocale":false,"canDeleteWebspace":null,"isPageDraft":null,"parentPath":"/developers/design-documents","parentWuid":"wuid:gx:359ef223e0fb14ac","siteLocale":"en","timeZone":"America/Los_Angeles","type":"text","title":"Idealized MediaStream Design","locale":"en","wuid":"wuid:gx:3c630d9b4c3641de","revision":3,"path":"/developers/design-documents/idealized-mediastream-design","isSiteRtlLocale":false,"pageInheritsPermissions":null,"name":"idealized-mediastream-design","canChangePath":true,"state":"","properties":{},"bidiEnabled":false,"currentTemplate":{"path":"/system/app/pagetemplates/text","title":"Web Page"}},"canPublishScriptToAnyone":true,"user":{"keyboardShortcuts":true,"sessionIndex":"","guest_":true,"displayNameOrEmail":"guest","userName":"guest","uid":"","renderMobile":false,"domain":"","namespace":"","hasWriteAccess":false,"namespaceUser":false,"primaryEmail":"guest","hasAdminAccess":false},"gadgets":{"baseUri":"/system/app/pages/gadgets"}};
  webspace.page.breadcrumbs = breadcrumbs;

  
  var JOT_siteRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

</script>
<script type="text/javascript">
                window.jstiming.load.tick('scl');
              </script>
<meta name="title" content="Idealized MediaStream Design - The Chromium Projects" />
<meta itemprop="name" content="Idealized MediaStream Design - The Chromium Projects" />
<meta property="og:title" content="Idealized MediaStream Design - The Chromium Projects" />
<meta name="description" content="Home of the Chromium Open Source Project" />
<meta itemprop="description" content="Home of the Chromium Open Source Project" />
<meta id="meta-tag-description" property="og:description" content="Home of the Chromium Open Source Project" />
<style type="text/css">
</style>
<link rel="stylesheet" type="text/css" href="https://ssl.gstatic.com/sites/p/56e332/system/app/themes/beigeandblue/standard-css-beigeandblue-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="../../_/rsrc/1441580320000/system/app/css/overlay.css%3Fcb=beigeandblueundefineda100%2525%2525150goog-ws-leftthemedefaultstandard.css" />
<link rel="stylesheet" type="text/css" href="../../_/rsrc/1441580320000/system/app/css/camelot/allthemes-view.css" />
<!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->
<title>Idealized MediaStream Design - The Chromium Projects</title>
<meta itemprop="image" content="https://lh4.googleusercontent.com/HN2JTb9zkbg98uWT5ed8imaPP-Ee7JSuUeAi22aoN6TV8VWViBa0gYQlpgCGiekw-DicKIvwcTMeHhFzcu2UO9z0Nly-4dnlQ08AjyJIJK1MuK0zddVXsKkl-Q" />
<meta property="og:image" content="https://lh4.googleusercontent.com/HN2JTb9zkbg98uWT5ed8imaPP-Ee7JSuUeAi22aoN6TV8VWViBa0gYQlpgCGiekw-DicKIvwcTMeHhFzcu2UO9z0Nly-4dnlQ08AjyJIJK1MuK0zddVXsKkl-Q" />
<script type="text/javascript">
                window.jstiming.load.tick('cl');
              </script>
</head>
<body xmlns="http://www.google.com/ns/jotspot" id="body" class=" en            ">
<div id="sites-page-toolbar" class="sites-header-divider">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-status" class="sites-status" style="display:none;"><div id="sites-notice" class="sites-notice" role="status" aria-live="assertive"> </div></div>
</div>
<div id="sites-chrome-everything-scrollbar">
<div id="sites-chrome-everything" class="">
<div id="sites-chrome-page-wrapper" style="direction: ltr">
<div id="sites-chrome-page-wrapper-inside">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-chrome-header-wrapper" style="height:auto;">
<table id="sites-chrome-header" class="sites-layout-hbox" cellspacing="0" style="height:auto;">
<tr class="sites-header-primary-row" id="sites-chrome-userheader">
<td id="sites-header-title" class="" role="banner"><div class="sites-header-cell-buffer-wrapper"><a href="../../index.html" id="sites-chrome-userheader-logo"><img id="logo-img-id" src="../../_/rsrc/1438879449147/config/customLogo.gif%3Frevision=3" alt="The Chromium Projects" class="sites-logo  " /></a><h2><a href="../../index.html" dir="ltr" id="sites-chrome-userheader-title">The Chromium Projects</a></h2></div></td><td class="sites-layout-searchbox  "><div class="sites-header-cell-buffer-wrapper"><form id="sites-searchbox-form" action="https://www.chromium.org/system/app/pages/search" role="search"><input type="hidden" id="sites-searchbox-scope" name="scope" value="search-site" /><input type="text" id="jot-ui-searchInput" name="q" size="20" value="" aria-label="Search this site" /><div id="sites-searchbox-button-set" class="goog-inline-block"><div role="button" id="sites-searchbox-search-button" class="goog-inline-block jfk-button jfk-button-standard" tabindex="0">Search this site</div></div></form></div></td>
</tr>
<tr class="sites-header-secondary-row" id="sites-chrome-horizontal-nav">
<td colspan="2" id="sites-chrome-header-horizontal-nav-container" role="navigation">
</td>
</tr>
</table>
</div>
<div id="sites-chrome-main-wrapper">
<div id="sites-chrome-main-wrapper-inside">
<table id="sites-chrome-main" class="sites-layout-hbox" cellspacing="0" cellpadding="{scmCellpadding}" border="0">
<tr>
<td id="sites-chrome-sidebar-left" class="sites-layout-sidebar-left initial" style="width:150px">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_7648876402527094" class="sites-embed" role="navigation"><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="../../chromium-projects.html" jotId="wuid:gx:10ae433dadbbab13" class="sites-navigation-link">Home</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../../Home.1.html" jotId="wuid:gx:43582b9d2029d3af" class="sites-navigation-link">Chromium</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../../chromium-os.1.html" jotId="wuid:gx:83df2ab1f8880ba" class="sites-navigation-link">Chromium OS</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_14720868319272995" class="sites-embed" role="navigation"><h4 class="sites-embed-title">Quick links</h4><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="../../for-testers/bug-reporting-guidelines.html" class="sites-navigation-link">Report bugs</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../discussion-groups.html" class="sites-navigation-link">Discuss</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../../system/app/pages/sitemap/hierarchy.html" jotId="wuid:gx:4b58a9a350ad12f" class="sites-navigation-link">网站地图</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_19690813310444355" class="sites-embed" role="navigation"><h4 class="sites-embed-title">Other sites</h4><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="http://blog.chromium.org/" class="sites-navigation-link">Chromium Blog</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="http://code.google.com/chrome/extensions/" class="sites-navigation-link">Google Chrome Extensions</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="https://developers.google.com/chrome/chrome-frame/" class="sites-navigation-link">Google Chrome Frame</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_19695218559354544" class="sites-embed" role="complementary"><h4 class="sites-embed-title"></h4><div class="sites-embed-content sites-embed-content-sidebar-textbox"><div dir="ltr"><span style="font-size:x-small">Except as otherwise </span><a href="http://developers.google.com/site-policies.html#restrictions"><span style="font-size:x-small">noted</span></a><span style="font-size:x-small">, the content of this page is licensed under a </span><a href="http://creativecommons.org/licenses/by/2.5/"><span style="font-size:x-small">Creative Commons Attribution 2.5 license</span></a><span style="font-size:x-small">, and examples are licensed under the </span><a href="http://src.chromium.org/viewvc/chrome/trunk/src/LICENSE" target="_blank"><span style="font-size:x-small">BSD License</span></a><span style="font-size:x-small">.<br /></span></div></div></div>
</td>
<td id="sites-canvas-wrapper">
<div id="sites-canvas" role="main">
<div id="goog-ws-editor-toolbar-container"> </div>
<div xmlns="http://www.w3.org/1999/xhtml" id="title-crumbs" style="">
<A href="../../developers.1.html" dir="ltr">For Developers</A>‎ &gt; ‎<A href="../design-documents.1.html" dir="ltr">Design Documents</A>‎ &gt; ‎
  </div>
<h3 xmlns="http://www.w3.org/1999/xhtml" id="sites-page-title-header" style="" align="left">
<span id="sites-page-title" dir="ltr" tabindex="-1" style="outline: none">Idealized MediaStream Design</span>
</h3>
<div id="sites-canvas-main" class="sites-canvas-main">
<div id="sites-canvas-main-content">
<table xmlns="http://www.w3.org/1999/xhtml" cellspacing="0" class="sites-layout-name-one-column sites-layout-hbox"><tbody><tr><td class="sites-layout-tile sites-tile-name-content-1"><div dir="ltr"><span><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:28px;font-family:Trebuchet MS;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Idealized MediaStream Design in Chrome</span></p><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Designed November 2013 by the </span><a href="https://code.google.com/p/chromium/wiki/PiranhaPlant" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">Piranha Plant</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> </span><a href="mailto:piranha-plant@chromium.org" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">team</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">. Document author </span><a href="mailto:joi@chromium.org" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">joi@chromium.org</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">.</span></p><h1 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Introduction"></a><span style="font-size:21px;font-family:Trebuchet MS;background-color:transparent;font-weight:normal;vertical-align:baseline;white-space:pre-wrap">Introduction</span></h1><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">This document describes the idealized design for MediaStreams (local and remote) that we are aiming for in Chrome. By idealized we mean that this is not the current design at the time of writing, but rather the design we want to incrementally move towards.</span></p><h1 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Background"></a><span style="font-size:21px;font-family:Trebuchet MS;background-color:transparent;font-weight:normal;vertical-align:baseline;white-space:pre-wrap">Background</span></h1><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The </span><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">MediaStream</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> specification has evolved from being focused around </span><a href="http://dev.w3.org/2011/webrtc/editor/webrtc.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">PeerConnections</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> for sending media to remote endpoints and &lt;audio&gt; and &lt;video&gt; tags for local playback, to a spec where streaming media can have multiple different endpoints, including the above as well as </span><a href="http://www.w3.org/TR/mediastream-recording/" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">recording</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> and </span><a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">WebAudio</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> and possibly more in the future.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Because of this heritage, Chrome’s current implementation of MediaStreams is heavily dependent on </span><a href="https://code.google.com/p/libjingle/" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">libjingle</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">, even for streams that are neither sent nor received via a PeerConnection.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">At the same time, the specification now seems relatively stable, and we are aware of various things we will want to be able to achieve in the near future that the current design is not well-suited for (examples include relaying, hardware capture devices that can encode directly to a transport encoding, hardware decoders that can directly render media, embedder-specific features that wish to act as endpoints for streaming media, and more).</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">This document assumes familiarity with the </span><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">MediaStream</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> and </span><a href="http://dev.w3.org/2011/webrtc/editor/webrtc.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">PeerConnection</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> HTML5 specifications, with Chrome's </span><a href="multi-process-architecture.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">multi-process architecture</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">, its </span><a href="../content-module.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">Content</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">, </span><a href="../../blink.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">Blink</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> and </span><a href="../../audio-video.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">Media</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> layers, as well as common </span><a href="http://www.chromium.org/developers/coding-style/important-abstractions-and-data-structures" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">abstractions</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> and approaches to </span><a href="threading.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">threading</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">.</span></p><h1 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Objectives"></a><span style="font-size:21px;font-family:Trebuchet MS;background-color:transparent;font-weight:normal;vertical-align:baseline;white-space:pre-wrap">Objectives</span></h1><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;color:rgb(34,34,34);vertical-align:baseline;white-space:pre-wrap">Objectives include:</span></p><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;color:rgb(34,34,34);vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="vertical-align:baseline;white-space:pre-wrap">Create the simplest design that will support features we expect to need in the future (see background section).</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="color:rgb(34,34,34);vertical-align:baseline;white-space:pre-wrap">Make life easier for Chrome developers using MediaStream.</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="color:rgb(34,34,34);vertical-align:baseline;white-space:pre-wrap">Improve quality, maintainability and readability/understandability of the MediaStream code.</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;color:rgb(34,34,34);vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="vertical-align:baseline;white-space:pre-wrap">Limit use of libjingle to Chrome’s implementation of PeerConnection.</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="color:rgb(34,34,34);vertical-align:baseline;white-space:pre-wrap">Balance concerns and priorities of the different teams that are or will be using MediaStreams in Chrome.</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="color:rgb(34,34,34);vertical-align:baseline;white-space:pre-wrap">Do the above without hurting our ability to produce the WebRTC.org deliverables, and without hurting interoperability between Chrome and software built on the WebRTC.org deliverables.</span></p></li></ul><h1 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Design"></a><span style="font-size:21px;font-family:Trebuchet MS;background-color:transparent;font-weight:normal;vertical-align:baseline;white-space:pre-wrap">Design</span></h1><h2 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Sources-Tracks-and-Sinks"></a><span style="font-size:17px;font-family:Trebuchet MS;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Sources, Tracks and Sinks</span><img height="515px;" src="https://lh4.googleusercontent.com/HN2JTb9zkbg98uWT5ed8imaPP-Ee7JSuUeAi22aoN6TV8VWViBa0gYQlpgCGiekw-DicKIvwcTMeHhFzcu2UO9z0Nly-4dnlQ08AjyJIJK1MuK0zddVXsKkl-Q" width="624px;" /></h2><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt;text-align:right"><span style="font-size:15px;font-family:Arial;background-color:transparent;font-style:italic;vertical-align:baseline;white-space:pre-wrap">Figure 1 - Overview of Sources, Tracks and Sinks. Local media capture assumed.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The main Blink-side concepts related to MediaStreams will remain as-is. These are WebMediaStream, WebMediaStreamTrack, and WebMediaStreamSource.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">In Content, there will be a content::MediaStreamTrack and content::MediaStreamSource, each with Audio and Video subclasses and each available to higher levels through the Content API. These will be directly owned by their Blink counterparts via their ExtraData field.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">A MediaStream is mostly just a collection of tracks and sources. The Blink-side representation of this collection should be sufficient, with no need for this collection concept in Content.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">A content::MediaStreamSource can be thought of as receiving raw data and processing it</span></p><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> (e.g. for echo cancellation and noise suppression) on behalf of one or more content::MediaStreamTrack objects.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">A media::MediaSink interface (with Audio and Video subclasses) can be implemented by Content and layers above it in order to register as a sink (and unregister prior to destruction) with a content::MediaStreamTrack, thereby receiving the audio or video bitstream from the track, and necessary metadata.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Sinks are not owned by the track they register with.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">A content::MediaStreamTrack will register with a content::MediaStreamSource (and unregister prior to destruction). The interface it registers will be a media::MediaSink. Additionally, on registration the track will provide the </span><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html#mediastreamconstraints" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">constraints</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> for the track, which among other things indicate which type of audio or video processing is desired.</span></p><br /><img height="333px;" src="https://lh5.googleusercontent.com/vVe5rDS6SzeAAygbYo3Ynrjq5UCH65dVTJidG708hpSuW6XvCVWPLWQiDVbvAP-01sJFcBtLpqNmPGY6LhsLen2z3psmsOzJOkaczSGG3zw98sycvrX_INRx3Q" width="624px;" /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt;text-align:right"><span style="font-size:15px;font-family:Arial;background-color:transparent;font-style:italic;vertical-align:baseline;white-space:pre-wrap">Figure 2 - Showing processing module ownership in a source.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">A source will own the processing modules for the tracks registered with it, and will create just one such module for each equivalent set of constraints. Shown here are audio processing modules or APMs, but in the future we expect to have something similar for video e.g. for scaling and/or cropping.</span></p><br /><h2 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Sinks-for-Media"></a><span style="font-size:17px;font-family:Trebuchet MS;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Sinks for Media</span></h2><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-Local-Sinks"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Local Sinks</span></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">In the Content and Blink layers, there will be local sink implementations, i.e. recipients of the audio and video media from a MediaStreamTrack, for &lt;audio&gt; and &lt;video&gt; tags, </span><a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">WebAudio</span><span style="font-size:15px;font-family:Arial;color:rgb(0,0,0);background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> </span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">and </span><a href="http://www.w3.org/TR/mediastream-recording/" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">recording</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">.</span></p><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-Remote-Destined-Sinks"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Remote-Destined Sinks</span></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The Content and Blink layers will also collaborate to enable piping the media from the various tracks in a MediaStream over a PeerConnection.</span></p><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-Application-Specific"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Application-Specific</span></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Layers embedding Content (e.g. the Chrome layer) may also implement application-specific sinks for MediaStreamTracks. These might be local or remote-destined.</span></p><br /><h2 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Push-Model-and-Synchronization"></a><span style="font-size:17px;font-family:Trebuchet MS;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Push Model and Synchronization</span></h2><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Above the level of sources, we will have a push model. Sources will push data to tracks, which in turn will push data to sinks.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Sources may either have raw data pushed to them (e.g. in the case of local media capture), or will need to pull data (e.g. in the case of media being received over a PeerConnection). This distinction will be invisible to everything above a source.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">A source will have methods to allow pushing media data into it. It will also allow registering a media::MediaProvider (which will have Audio and Video subclasses) from which the source can pull. The source takes ownership of the MediaProvider.</span></p><br /><img height="448px;" src="https://lh3.googleusercontent.com/XHk0O8xJDiezATLchY1z6pI-aeq9zXlMvsN4BUfstJZs6mk0FzZTAxpfa3xbxUNUfkSNihpobofg9EQGGMfgBs5apJJXq4xW29QQMWJKU_WGsnHSpOTdjwk5hQ" width="624px;" /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt;text-align:right"><span style="font-size:15px;font-family:Arial;background-color:transparent;font-style:italic;vertical-align:baseline;white-space:pre-wrap">Figure 3 - Pushed to source vs. pulled by source</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">When audio is being played locally that needs to be pulled by a source, the “heartbeat” that will cause the source to pull will be the heartbeat of the local audio output device, which will be sent over IPC and end up on the capture thread. When there is no such heartbeat available (e.g. audio is not being played, data is just being relayed to another peer over a PeerConnection or only video is playing) an artificial heartbeat for pulling from MediaProviders and pushing out from the source will be generated on the capture thread.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The reason to use the audio output device as the heartbeat is to ensure that data is pulled at the right rate and does not fall behind or start buffering up.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Both audio and video data, from all sources, will have timestamps at all levels above the source (the source will add the timestamp if it receives or pulls data that is not already timestamped). Media data will also have a GUID identifying the clock that provided the timestamps. Timestamps will allow synchronization between audio and video, e.g. dropping video frames to catch up with audio when video falls behind. A GUID will allow e.g. synchronization of two tracks that were sent over separate PeerConnections but originated from the same machine. TODO: Specify this in more detail before implementing.</span></p><br /><h2 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-MediaStreams-with-Local-Capture"></a><span style="font-size:17px;font-family:Trebuchet MS;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">MediaStreams with Local Capture</span></h2><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">To create a MediaStream capturing local audio and/or video, the </span><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html" style="text-decoration:none"><span style="font-size:15px;font-family:Arial;color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">getUserMedia</span></a><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> API is used. The result is a MediaStream with a collection of MediaStreamTracks each of which has a locally-originated MediaStreamSource.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">In this section, we add some detail on the local audio and video pipelines for such MediaStreams.</span></p><br /><img height="510px;" src="https://lh5.googleusercontent.com/TP8PmdhcA59qxU_1azStCn61FPUraoeEG2kw4Bz_-oyvZpZMoUcDYTtUurXwFnVoPAaBIPxhr5EITQMLbHrzehzq8y6wgM9ibdR90F11FiowFAyhEdjQspA-nQ" width="414px;" /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt;text-align:right"><span style="font-size:15px;font-family:Arial;background-color:transparent;font-style:italic;vertical-align:baseline;white-space:pre-wrap">Figure 4 - Detail on getUserMedia request.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Figure 4 shows the main players in a getUserMedia request. A UserMediaRequest is created on the Blink side, the request to open devices ends up in the CaptureDeviceManager on the browser side, and the UserMediaHandler is responsible for creating the hierarchy of a WebMediaStream object on the blink side, and the blink- and Content-side source objects for each opened device, and the initial track for each source.</span></p><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-Local-Audio-Pipeline"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Local Audio Pipeline</span><img height="476px;" src="https://lh4.googleusercontent.com/O0MUgRkOUg0sdLy7Q4JlvJ1axESTtUPBe5mut532JBX4dzgoyh1v9cvNUQypGLqdLQ9be0T7Trv0qfihEpNoEsnFeM7grcDWBqVyFxSYzAmct1eh76gaez8DtA" width="426px;" /></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt;text-align:right"><span style="font-size:15px;font-family:Arial;background-color:transparent;font-style:italic;vertical-align:baseline;white-space:pre-wrap">Figure 5 - Local Audio Pipeline Overview</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">When a local audio capture device is opened, the end result is that there is an AudioStream instance on the browser side that receives the bitstream from the physical device, and an AudioInputDevice instance on the renderer side that, in the abstract, is receiving the same bitstream (over layers of IPC and such, as is typical in Chrome). The AudioInputDevice pushes the audio into the MediaStreamAudioSource.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Setting up an AudioInputDevice/AudioStream pair involves several players. At a somewhat abstract level:</span></p><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The MediaStreamAudioSource has a session ID, which receives it on creation, in step 8 of figure 4;</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">This session ID is passed through the various layers. The AudioInputHost looks up session ID-keyed information in the AudioInputDeviceManager, then using that information causes the AudioInputController to create an AudioStream for the device via the AudioManager.</span></p></li></ul><br /><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-Local-Video-Pipeline"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Local Video Pipeline</span></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Similar to the audio capture pipeline. Key players are the browser/renderer pair VideoCaptureController and VideoCaptureClient (analogous to AudioStream and AudioInputDevice), and the browser-side VideoCaptureHost and VideoCaptureManager.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;font-family:Arial;font-size:15px;white-space:pre-wrap;line-height:1.15">TODO: Finish this section and provide a chart matching the class hierarchy and names between the two.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt;text-align:right"><span style="font-size:15px;font-family:Arial;background-color:transparent;font-style:italic;vertical-align:baseline;white-space:pre-wrap">Figure 6 (placeholder) - Local Video Pipeline Overview</span></p><h2 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-MediaStreams-With-PeerConnection"></a><span style="font-size:17px;font-family:Trebuchet MS;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">MediaStreams With PeerConnection</span></h2><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-Sent-Over-PeerConnection"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Sent Over PeerConnection</span><img height="359px;" src="https://lh4.googleusercontent.com/0sq2VE9aHu2tNBW-sL4brXuYwqhbazksb4OnToj8lxPtNmNTUaIGOsBNTjGnZ7FnqmXJQzn3HfYp-fWjgigtV2nZtMPJa2eNOaJPNJvXLCL18rSjSJ8_yyCn9Q" width="624px;" /></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt;text-align:right"><span style="font-size:15px;font-family:Arial;background-color:transparent;font-style:italic;vertical-align:baseline;white-space:pre-wrap">Figure 7 - MediaStream Sent Over PeerConnection</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">When a web page calls PeerConnection::AddStream to add a MediaStream to a connection, the sequence of events will be as follows:</span></p><ol style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">content::RTCPeerConnectionHandler will add a SentPeerConnectionMediaStream to its map of such objects, keyed by the WebMediaStream that is being added.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">SentPeerConnectionMediaStream creates the libjingle-side webrtc::MediaStream.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">For each content::MediaStreamTrack, it creates a webrtc::MediaStreamTrack, and a content::LibjingleSentTrackAdapter which will push media bits to the webrtc::MediaStreamTrack.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">SentPeerConnectionMediaStream registers the LibjingleSentTrackAdapter as a sink on the content::MediaStreamTrack.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Once all adapters and libjingle-side tracks are set up, SentPeerConnectionMediaStream adds the webrtc::MediaStream to the webrtc::PeerConnection.</span></p></li></ol><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Ownership is such that the WebMediaStream and related objects on the Blink side own the content::MediaStreamSource and its tracks, and the SentPeerConnectionMediaStream owns the libjingle object hierarchy and the LIbjingleSentTrackAdapter (likely one implementation for audio, and one for video).</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">In this structure, the only usage of libjingle in Content is by LibjingleSentTrackAdapter and by SentPeerConnectionMediaStream. The rest of the MediaStream implementation in Content and Blink does not know about libjingle at all. Note also that no libjingle-side objects except for the PeerConnection are created until a MediaStream is added to it.</span></p><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-Received-Via-PeerConnection"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Received Via PeerConnection</span><img height="332px;" src="https://lh4.googleusercontent.com/TULqa8D9Rb6grUNNNZ8srWtwt0hv9ZPV7aoi2vLoX-YVa4gNNSUK6MAchJdkVCB43kenkyxW1Bb3hK0b_ibwHj51BYuxeANLidyq7kAAZ9mda4-COU_qLuN6_g" width="624px;" /></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt;text-align:right"><span style="font-size:15px;font-family:Arial;background-color:transparent;font-style:italic;vertical-align:baseline;white-space:pre-wrap">Figure 8 - MediaStream Received via PeerConnection</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">When a webrtc::PeerConnection receives a new remote MediaStream, the sequence of events is as follows:</span></p><ol style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">On the libjingle side, the webrtc::MediaStream and its tracks are created. Note that these tracks do not have a source.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">content::RTCPeerConnectionHandler receives an onAddStream notification. It creates a ReceivedPeerConnectionMediaStream and adds it to a map of such objects keyed by MediaStream labels for MediaStreams received over a PeerConnection.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The ReceivedPeerConnectionMediaStream creates the Blink-side object representing the MediaStream.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">It then creates one local Source per received track. This is important; since received tracks don’t have sources, locally they act like sources.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">It then creates one local Track per local Source.</span></p></li><li dir="ltr" style="list-style-type:decimal;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Finally, in the audio case it creates a content::LibjingleReceivedTrackAdapter that retrieves data from the webrtc::MediaStreamTrack, and registers it as a media::MediaProvider for the local content::MediaStreamSource. The source will pull data via the MediaProvider interface. In the video case, the adapter will push video to the source.</span></p></li></ol><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Ownership is such that the WebMediaStream and related objects on the Blink side are referenced by the ReceivedPeerConnectionMediaStream, and they own the content::MediaStreamSource and its tracks. The LibjingleReceivedTrackAdapter is owned by the content::MediaStreamSource object. content::RTCPeerConnectionHandler owns the webrtc::PeerConnection, which owns the libjingle-side object hierarchy.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">In this structure, the only usage of libjingle in Content is by LibjingleReceivedTrackAdapter, ReceivedPeerConnectionMediaStream and RTCPeerConnectionHandler. The rest of the MediaStream implementation in Content and Blink does not know about libjingle at all. Note also that no libjingle-side objects except for the PeerConnection are created until the PeerConnection receives a new MediaStream from a peer.</span></p><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-MediaStream-Mutability"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">MediaStream Mutability</span></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">This section explains how addition and removal of MediaStreamTracks to a MediaStream being sent/received over a PeerConnection will be done.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">In the case where a track is added to a local MediaStream, RTCPeerConnectionHandler will receive a notification that this has happened (TODO: specify how it receives this notification). It will check if it has a SentPeerConnectionMediaStream for the given MediaStream. If so, it will create the libjingle-side track and add it to the libjingle-side MediaStream, as well as creating the requisite LibjingleSentTrackAdapter and registering it as a sink for the local track that was added to the MediaStream.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">When a track is added to a MediaStream received over a PeerConnection, the libjingle-side code will add the webrtc::MediaStreamTrack to the webrtc::MediaStream. The content::ReceivedPeerConnectionMediaStream object (which observes webrtc::MediaStream) will receive a notification that a track was added, and will add a Blink- and Content-side source and track to the Blink-side MediaStream it already owns. It will create and own a LibjingleReceivedTrackAdapter, configure it to retrieve media from the libjingle-side track, and set it as the media::MediaProvider for the local content::MediaStreamSource (see previous section, Received via PeerConnection).</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">It is important to note that when a track is added to or removed from a MediaStream that is not being sent over or received via a PeerConnection, the libjingle code will not be involved in any way and no libjingle-side objects will be created or destroyed.</span></p><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-NetEQ"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">NetEQ</span></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">NetEQ is a subsystem that is fed an input stream of RTP packets carrying encoded audio data, and from which client code pulls decoded audio. When audio is pulled out of it, NetEQ attempts to create the best audio possible given the data available from the network at that point (which may be incomplete, e.g. in the face of packet loss or packets arriving out of order).</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Currently, there is a single NetEQ for audio on a MediaStream received over a PeerConnection, and the NetEQ sits at the libjingle level.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Several medium-term usage scenarios would be better served if we had more control over where to place the NetEQ. Two examples are:</span></p><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Relaying audio data from one peer to another peer. In this case we might want to have no decoding done on the data whatsoever, and therefore skip the NetEQ.</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><a href="http://www.w3.org/TR/mediastream-recording/" style="text-decoration:none"><span style="color:rgb(17,85,204);background-color:transparent;text-decoration:underline;vertical-align:baseline;white-space:pre-wrap">Recording</span></a><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap"> audio. Since recording does not have the same near-real-time demands as does a &lt;video&gt; tag showing a live video/audio chat with a remote peer, it can afford to let more audio data buffer up in the NetEQ before it starts pulling audio from it, and possibly even to delay the next pull up to some maximum time if the NetEQ reports that it does not have full audio data yet. If you are recording audio at the same time as playing it, this implies you would want one NetEQ that is pulled out of at near real-time for playing the audio, and a separate one that is pulled out of more slowly for recording, since this will improve the quality of the recorded audio (fewer missing packets of audio data).</span></p></li></ul><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">To fulfill the above needs, we plan to look into moving the NetEQ to the same layer as the intended location of the APM (see Figure 2). This would allow individual tracks on a source to set up the NetEQ using their desired constraints, and in the scenarios above would allow you to have a track that receives the raw audio data without it being decoded, or to clone your near-real-time track and set the constraints on the clone to get a track with NetEQ usage more suited to recording.</span></p><h2 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-MediaStream-Threading-Model"></a><span style="font-size:17px;font-family:Trebuchet MS;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">MediaStream Threading Model</span></h2><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">TODO: This needs more work to flesh it out on the video side, and to figure out the idealized design. The following mostly documents the current situation for audio. For video, a separate capture thread may not be needed and for some clients it is undesirable to have a separate thread for capture in both the audio and video cases.</span></p><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">We expect the current threading model around MediaStreams in Content to remain mostly unchanged. On the renderer side, the main threads are:</span></p><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The main renderer thread (RenderThread). This is where most signaling takes place.</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">A single media render thread. This is where media is prepared for output. This thread takes care of things such as resampling to APM format to provide the original image for echo cancellation (may happen 2 times or more; possibly some of this can be avoided).</span></p></li><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">A single media capture thread. This thread does the following:</span></p></li><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:circle;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">processing</span></p></li><li dir="ltr" style="list-style-type:circle;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">resampling</span></p></li><li dir="ltr" style="list-style-type:circle;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">AEC, noise suppression, AGC</span></p></li></ul></ul><br /><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">On the browser side, messages to/from the renderer are sent/received on the IPC thread. There are also media render and media capture threads similar to the renderer side, whose job is to open physical devices and write to or read from them. The browser-side media render thread may also do resampling of audio when the renderer is providing audio in a different format than the browser side needs, but this should be minimized by reconfiguring the renderer side when needed.</span></p><h3 dir="ltr" style="line-height:1.15;margin-top:8pt;margin-bottom:0pt"><a name="TOC-PeerConnection-Threading"></a><span style="font-family:Trebuchet MS;color:rgb(102,102,102);background-color:transparent;vertical-align:baseline;white-space:pre-wrap">PeerConnection Threading</span></h3><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">For PeerConnection, there are two main threads:</span></p><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The “signaling thread” which in Chrome is actually the same as the RenderThread. The signaling thread is where the “API” for libjingle lives.</span></p></li><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:circle;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">This is a bit confusing because calls from the RenderThread are made to a proxy class, that in the general case would post the tasks to a different thread. In the special case where the calling and destination threads are the same, this ends up as a simple same-thread dispatch, i.e. equivalent to a method call.</span></p></li><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:square;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">This is a libjingle thing, other clients desire thread-independent calling.</span></p></li><li dir="ltr" style="list-style-type:square;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">It would be nice to get rid of the need for the proxy but we may need it for Java code in Android. TODO: Check with Ami.</span></p></li></ul></ul><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">The worker thread (created and owned within libjingle), of which there is initially one, but may be more.</span></p></li><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:circle;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">This is separate from the signaling thread.</span></p></li><li dir="ltr" style="list-style-type:circle;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">It prepares network packets.</span></p></li><li dir="ltr" style="list-style-type:circle;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">It calls libjingle for media work.</span></p></li></ul></ul><h2 dir="ltr" style="line-height:1.15;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Directory-Structure"></a><span style="font-size:17px;font-family:Trebuchet MS;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Directory Structure</span></h2><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline;white-space:pre-wrap">We plan to make a couple of minor changes to the directory structure under //content to help better manage dependencies and more easily put in place an appropriate ownership structure:</span></p><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Code that #includes anything from libjingle will be isolated to //content/renderer/media/webrtc.</span></p></li><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:circle;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Outside of this directory, //content will not directly depend on libjingle.</span></p></li></ul><li dir="ltr" style="list-style-type:disc;font-size:15px;font-family:Arial;background-color:transparent;vertical-align:baseline"><p dir="ltr" style="line-height:1.15;margin-top:0pt;margin-bottom:0pt"><span style="background-color:transparent;vertical-align:baseline;white-space:pre-wrap">Code related to the HTML5 MediaStream spec will be isolated to //content/{common|browser|browser/renderer_host|renderer}/media/media_stream.</span></p></li></ul><br /></span></div></td></tr></tbody></table>
</div> 
</div> 
<div id="sites-canvas-bottom-panel">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-subpages"> </div>
<div id="sites-attachments-container">
</div>
<a xmlns="http://www.w3.org/1999/xhtml" name="page-comments"></a>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-comments"><div class="sites-comment-docos-wrapper"><div class="sites-comment-docos"><div class="sites-comment-docos-background"></div><div class="sites-comment-docos-header"><div class="sites-comment-docos-header-title">Comments</div></div><div id="sites-comment-docos-pane" class="sites-comment-docos-pane"></div></div></div></div>
</div>
</div> 
</td> 
</tr>
</table> 
</div> 
</div> 
<div id="sites-chrome-footer-wrapper">
<div id="sites-chrome-footer-wrapper-inside">
<div id="sites-chrome-footer">
</div>
</div>
</div>
</div> 
</div> 
<div id="sites-chrome-adminfooter-container">
<div xmlns="http://www.w3.org/1999/xhtml" class="sites-adminfooter" role="navigation"><p><a class="sites-system-link" href="https://www.google.com/a/UniversalLogin?service=jotspot&amp;continue=https://sites.google.com/a/chromium.org/dev/developers/design-documents/idealized-mediastream-design">Sign in</a><span aria-hidden="true">|</span><a class="sites-system-link" href="../../system/app/pages/recentChanges.html">Recent Site Activity</a><span aria-hidden="true">|</span><a class="sites-system-link" href="../../system/app/pages/reportAbuse.html" target="_blank">Report Abuse</a><span aria-hidden="true">|</span><a class="sites-system-link" href="javascript:;" onclick="window.open(webspace.printUrl)">Print Page</a><span aria-hidden="true">|</span><span class="sites-system-link">Powered By</span> <b class="powered-by"><a href="http://sites.google.com">Google Sites</a></b></p></div>
</div>
</div> 
</div> 
<div id="sites-chrome-onebar-footer">
</div>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('sjl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" src="https://ssl.gstatic.com/sites/p/56e332/system/js/jot_min_view__en.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('jl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml">
      
          sites.core.Analytics.createTracker();
          sites.core.Analytics.trackPageview();
        
    </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
                    sites.Searchbox.initialize(
                        'sites-searchbox-search-button',
                        {"object":[]}['object'],
                        'search-site',
                        {"label":"Configure search options...","url":"/system/app/pages/admin/settings"});
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
      gsites.HoverPopupMenu.createSiteDropdownMenus('sites-header-nav-dropdown', false);
    </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("7648876402527094", "Navigation", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_7648876402527094');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("14720868319272995", "Quick links", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_14720868319272995');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("19690813310444355", "Other sites", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_19690813310444355');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
              new sites.CommentPane('//docs.google.com/comments/d/AAHRpnXvrAwjAfmld0ObrebBiGRq9GouoxhcQIiDJ5JmMjhZ7zGHImy0ofQf4xpzMHKIZ9IsHmz6Avw8h4rg_3xp7829SCRy8rTgj652aWhMXACSB382qBqrf-fhKC1nm8arGG1q2H4eH/api/js?anon=true',
                  false, false);
            </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
  setTimeout(function() {
    var fingerprint = gsites.date.TimeZone.getFingerprint([]);
    gsites.Xhr.send('https://www.chromium.org/_/tz', null, null, 'GET', null, null, { afjstz: fingerprint });
  }, 500);
</script>
<script xmlns="http://www.w3.org/1999/xhtml">
                    window.onload = function() {
                      if (false) {
                        JOT_setMobilePreview();
                      }
                      var loadTimer = window.jstiming.load;
                      loadTimer.tick("ol");
                      loadTimer["name"] = "load," + webspace.page.type + ",user_page";
                      window.jstiming.report(loadTimer, {}, 'https://gg.google.com/csi');
                    }
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
        JOT_insertAnalyticsCode(false,
            false);
      </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    var maestroRunner = new gsites.pages.view.SitesMaestroRunner(
        webspace, "en");
    maestroRunner.initListeners();
    maestroRunner.installEditRender();
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
  //<![CDATA[
    // Decorate any fastUI buttons on the page with a class of 'goog-button'.
    if (webspace.user.hasWriteAccess) {
      JOT_decorateButtons();
    }

    // Fires delayed events.
    (function() {
      JOT_fullyLoaded = true;
      var delayedEvents = JOT_delayedEvents;
      for (var x = 0; x < delayedEvents.length; x++) {
        var event = delayedEvents[x];
        JOT_postEvent(event.eventName, event.eventSrc, event.payload);
      }
      JOT_delayedEvents = null;
      JOT_postEvent('pageLoaded');
    })();
  //]]>
</script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    JOT_postEvent('decorateGvizCharts');
  </script>
<script type="text/javascript">
          JOT_setupPostRenderingManager();
        </script>
<script type="text/javascript">
          JOT_postEvent('renderPlus', null, 'sites-chrome-main');
        </script>
<div id="server-timer-div" style="display:none"> </div>
<script type="text/javascript">
          window.jstiming.load.tick('render');
          JOT_postEvent('usercontentrendered', this);
        </script>
</body>
</html>
