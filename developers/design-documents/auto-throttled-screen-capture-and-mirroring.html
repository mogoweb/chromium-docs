<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://schema.org/WebPage">
<head>
<meta http-equiv="X-UA-Compatible" content="chrome=1" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var e="wtsrt_",g="tbsd_",h="tbnd_",k="start",l="_wtsrt",m="_tbnd",n="CSI/";(function(){function f(a){this.t={};this.tick=function(a,c,b){this.t[a]=[void 0!=b?b:(new Date).getTime(),c];if(void 0==b)try{window.console.timeStamp(n+a)}catch(d){}};this.tick(k,null,a)}var a;window.performance&&(a=window.performance.timing);var p=a?new f(a.responseStart):new f;window.jstiming={Timer:f,load:p};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick(l,void 0,c),b.tick(e,l,d),b.tick(g,e))}try{a=null,
window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick(m,void 0,window.chrome.csi().startE),b.tick(h,m,c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick(m,void 0,window.external.startE),b.tick(h,m,c))),a&&(window.jstiming.pt=a)}catch(q){}})(); })()
</script>
<link rel="shortcut icon" href="../../_/rsrc/1354323194313/favicon.ico" type="image/x-icon" />
<link rel="apple-touch-icon" href="https://ssl.gstatic.com/sites/p/56e332/system/app/images/apple-touch-icon.png" type="image/png" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var d="",g="__duration__",h="function";function k(c){return document.getElementById(c)}window.byId=k;function l(c){return c.replace(/^\s+|\s+$/g,d)}window.trim=l;var m=[],n=0;window.JOT_addListener=function(c,a,b){var e=new String(n++);c={eventName:c,handler:a,compId:b,key:e};m.push(c);return e};window.JOT_removeListenerByKey=function(c){for(var a=0;a<m.length;a++)if(m[a].key==c){m.splice(a,1);break}};
window.JOT_removeAllListenersForName=function(c){for(var a=0;a<m.length;a++)m[a].eventName==c&&m.splice(a,1)};window.JOT_postEvent=function(c,a,b){var e={eventName:c,eventSrc:a||{},payload:b||{}};if(window.JOT_fullyLoaded)for(a=m.length,b=0;b<a&&b<m.length;b++){var f=m[b];f&&f.eventName==c&&(e.listenerCompId=f.compId||d,(f=typeof f.handler==h?f.handler:window[f.handler])&&f(e))}else window.JOT_delayedEvents.push({eventName:c,eventSrc:a,payload:b})};window.JOT_delayedEvents=[];
window.JOT_fullyLoaded=!1;window.JOT_formatRelativeToNow=function(c,a){var b=((new Date).getTime()-c)/6E4;if(1440<=b||0>b)return null;var e=0;60<=b&&(b/=60,e=2);2<=b&&e++;return a?window.JOT_siteRelTimeStrs[e].replace(g,Math.floor(b)):window.JOT_userRelTimeStrs[e].replace(g,Math.floor(b))}; })()
</script>
<script>

  

  var breadcrumbs = [{"path":"/developers","deleted":false,"title":"For Developers","dir":"ltr"},{"path":"/developers/design-documents","deleted":false,"title":"Design Documents","dir":"ltr"},{"path":"/developers/design-documents/auto-throttled-screen-capture-and-mirroring","deleted":false,"title":"Auto-Throttled Screen Capture and Mirroring","dir":"ltr"}];
  var JOT_clearDotPath = 'https://ssl.gstatic.com/sites/p/56e332/system/app/images/cleardot.gif';

  
  var JOT_userRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

  
  

  

  var webspace = {"enableAnalytics":true,"pageSharingId":"jotspot_page","enableUniversalAnalytics":false,"sharingPolicy":"OPENED_WITH_INDICATOR","siteTitle":"The Chromium Projects","isStartPageEnabled":true,"adsensePublisherId":null,"features":{"languageSelectDefaultTextSetToDefault":true,"validateClientGvizDataSourceUrls":true,"moreMobileStyleImprovements":true,"newInsertMenuIcons":true,"accessibleSortingButtons":true,"domainAnalyticsInGAOnly":true,"noCaptcha":true,"fileCabinetScreenReaderFix":true,"updatedTosAndPrivacyLinks":null,"pageDrafts":false,"mobileOrientationFix":true,"plusBadge":false,"pdfEmbedSupport":false,"jsClickFix":true},"isPublic":true,"isConsumer":false,"serverFlags":{"cajaBaseUrl":"//www.gstatic.com/caja","cajaDebugMode":false},"onepickBaseUrl":"https://docs.google.com","domainAnalyticsAccountId":"","plusPageId":"","signInUrl":"https://www.google.com/a/SelectSession?continue\u003dhttps://sites.google.com/a/chromium.org/dev/developers/design-documents/auto-throttled-screen-capture-and-mirroring\u0026service\u003djotspot","analyticsAccountId":"UA-5484340-1","scottyUrl":"/_/upload","homePath":"/","siteNoticeUrlEnabled":null,"plusPageUrl":"","adsensePromoClickedOrSiteIneligible":true,"csiReportUri":"https://gg.google.com/csi","sharingId":"jotspot","termsUrl":"//www.google.com/intl/en/policies/terms/","gvizVersion":1,"editorResources":{"sitelayout":["https://ssl.gstatic.com/sites/p/56e332/system/app/css/sitelayouteditor.css"],"text":["https://ssl.gstatic.com/sites/p/56e332/system/js/codemirror.js","https://ssl.gstatic.com/sites/p/56e332/system/app/css/codemirror_css.css","https://ssl.gstatic.com/sites/p/56e332/system/js/trog_edit__en.js","https://ssl.gstatic.com/sites/p/56e332/system/app/css/trogedit.css","/_/rsrc/1441580320000/system/app/css/editor.css","https://ssl.gstatic.com/sites/p/56e332/system/app/css/codeeditor.css","/_/rsrc/1441580320000/system/app/css/camelot/editor-jfk-wlb.css"]},"sharingUrlPrefix":"/_/sharing","isAdsenseEnabled":true,"domain":"chromium.org","baseUri":"","name":"dev","siteTemplateId":false,"siteNoticeRevision":null,"siteNoticeUrlAddress":null,"siteNoticeMessage":null,"page":{"isRtlLocale":false,"canDeleteWebspace":null,"isPageDraft":null,"parentPath":"/developers/design-documents","parentWuid":"wuid:gx:359ef223e0fb14ac","siteLocale":"en","timeZone":"America/Los_Angeles","type":"text","title":"Auto-Throttled Screen Capture and Mirroring","locale":"en","wuid":"wuid:gx:3b72b0e24f40ae5","revision":6,"path":"/developers/design-documents/auto-throttled-screen-capture-and-mirroring","isSiteRtlLocale":false,"pageInheritsPermissions":null,"name":"auto-throttled-screen-capture-and-mirroring","canChangePath":true,"state":"","properties":{},"bidiEnabled":false,"currentTemplate":{"path":"/system/app/pagetemplates/text","title":"Web Page"}},"canPublishScriptToAnyone":true,"user":{"keyboardShortcuts":true,"sessionIndex":"","guest_":true,"displayNameOrEmail":"guest","userName":"guest","uid":"","renderMobile":false,"domain":"","namespace":"","hasWriteAccess":false,"namespaceUser":false,"primaryEmail":"guest","hasAdminAccess":false},"gadgets":{"baseUri":"/system/app/pages/gadgets"}};
  webspace.page.breadcrumbs = breadcrumbs;

  
  var JOT_siteRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

</script>
<script type="text/javascript">
                window.jstiming.load.tick('scl');
              </script>
<meta name="title" content="Auto-Throttled Screen Capture and Mirroring - The Chromium Projects" />
<meta itemprop="name" content="Auto-Throttled Screen Capture and Mirroring - The Chromium Projects" />
<meta property="og:title" content="Auto-Throttled Screen Capture and Mirroring - The Chromium Projects" />
<meta name="description" content="Home of the Chromium Open Source Project" />
<meta itemprop="description" content="Home of the Chromium Open Source Project" />
<meta id="meta-tag-description" property="og:description" content="Home of the Chromium Open Source Project" />
<style type="text/css">
</style>
<link rel="stylesheet" type="text/css" href="https://ssl.gstatic.com/sites/p/56e332/system/app/themes/beigeandblue/standard-css-beigeandblue-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="../../_/rsrc/1441580320000/system/app/css/overlay.css%3Fcb=beigeandblueundefineda100%2525%2525150goog-ws-leftthemedefaultstandard.css" />
<link rel="stylesheet" type="text/css" href="../../_/rsrc/1441580320000/system/app/css/camelot/allthemes-view.css" />
<!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->
<title>Auto-Throttled Screen Capture and Mirroring - The Chromium Projects</title>
<meta itemprop="image" content="/_/rsrc/1438879449147/config/customLogo.gif?revision=3" />
<meta property="og:image" content="/_/rsrc/1438879449147/config/customLogo.gif?revision=3" />
<script type="text/javascript">
                window.jstiming.load.tick('cl');
              </script>
</head>
<body xmlns="http://www.google.com/ns/jotspot" id="body" class=" en            ">
<div id="sites-page-toolbar" class="sites-header-divider">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-status" class="sites-status" style="display:none;"><div id="sites-notice" class="sites-notice" role="status" aria-live="assertive"> </div></div>
</div>
<div id="sites-chrome-everything-scrollbar">
<div id="sites-chrome-everything" class="">
<div id="sites-chrome-page-wrapper" style="direction: ltr">
<div id="sites-chrome-page-wrapper-inside">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-chrome-header-wrapper" style="height:auto;">
<table id="sites-chrome-header" class="sites-layout-hbox" cellspacing="0" style="height:auto;">
<tr class="sites-header-primary-row" id="sites-chrome-userheader">
<td id="sites-header-title" class="" role="banner"><div class="sites-header-cell-buffer-wrapper"><a href="../../index.html" id="sites-chrome-userheader-logo"><img id="logo-img-id" src="../../_/rsrc/1438879449147/config/customLogo.gif%3Frevision=3" alt="The Chromium Projects" class="sites-logo  " /></a><h2><a href="../../index.html" dir="ltr" id="sites-chrome-userheader-title">The Chromium Projects</a></h2></div></td><td class="sites-layout-searchbox  "><div class="sites-header-cell-buffer-wrapper"><form id="sites-searchbox-form" action="https://www.chromium.org/system/app/pages/search" role="search"><input type="hidden" id="sites-searchbox-scope" name="scope" value="search-site" /><input type="text" id="jot-ui-searchInput" name="q" size="20" value="" aria-label="Search this site" /><div id="sites-searchbox-button-set" class="goog-inline-block"><div role="button" id="sites-searchbox-search-button" class="goog-inline-block jfk-button jfk-button-standard" tabindex="0">Search this site</div></div></form></div></td>
</tr>
<tr class="sites-header-secondary-row" id="sites-chrome-horizontal-nav">
<td colspan="2" id="sites-chrome-header-horizontal-nav-container" role="navigation">
</td>
</tr>
</table>
</div>
<div id="sites-chrome-main-wrapper">
<div id="sites-chrome-main-wrapper-inside">
<table id="sites-chrome-main" class="sites-layout-hbox" cellspacing="0" cellpadding="{scmCellpadding}" border="0">
<tr>
<td id="sites-chrome-sidebar-left" class="sites-layout-sidebar-left initial" style="width:150px">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_7648876402527094" class="sites-embed" role="navigation"><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="../../chromium-projects.html" jotId="wuid:gx:10ae433dadbbab13" class="sites-navigation-link">Home</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../../Home.1.html" jotId="wuid:gx:43582b9d2029d3af" class="sites-navigation-link">Chromium</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../../chromium-os.1.html" jotId="wuid:gx:83df2ab1f8880ba" class="sites-navigation-link">Chromium OS</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_14720868319272995" class="sites-embed" role="navigation"><h4 class="sites-embed-title">Quick links</h4><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="../../for-testers/bug-reporting-guidelines.html" class="sites-navigation-link">Report bugs</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../discussion-groups.html" class="sites-navigation-link">Discuss</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="../../system/app/pages/sitemap/hierarchy.html" jotId="wuid:gx:4b58a9a350ad12f" class="sites-navigation-link">网站地图</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_19690813310444355" class="sites-embed" role="navigation"><h4 class="sites-embed-title">Other sites</h4><div class="sites-embed-content sites-sidebar-nav"><ul role="navigation" jotId="navList"><li class="nav-first "><div dir="ltr" style="padding-left: 5px;"><a href="http://blog.chromium.org/" class="sites-navigation-link">Chromium Blog</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="http://code.google.com/chrome/extensions/" class="sites-navigation-link">Google Chrome Extensions</a></div></li><li class=""><div dir="ltr" style="padding-left: 5px;"><a href="https://developers.google.com/chrome/chrome-frame/" class="sites-navigation-link">Google Chrome Frame</a></div></li></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_19695218559354544" class="sites-embed" role="complementary"><h4 class="sites-embed-title"></h4><div class="sites-embed-content sites-embed-content-sidebar-textbox"><div dir="ltr"><span style="font-size:x-small">Except as otherwise </span><a href="http://developers.google.com/site-policies.html#restrictions"><span style="font-size:x-small">noted</span></a><span style="font-size:x-small">, the content of this page is licensed under a </span><a href="http://creativecommons.org/licenses/by/2.5/"><span style="font-size:x-small">Creative Commons Attribution 2.5 license</span></a><span style="font-size:x-small">, and examples are licensed under the </span><a href="http://src.chromium.org/viewvc/chrome/trunk/src/LICENSE" target="_blank"><span style="font-size:x-small">BSD License</span></a><span style="font-size:x-small">.<br /></span></div></div></div>
</td>
<td id="sites-canvas-wrapper">
<div id="sites-canvas" role="main">
<div id="goog-ws-editor-toolbar-container"> </div>
<div xmlns="http://www.w3.org/1999/xhtml" id="title-crumbs" style="">
<A href="../../developers.1.html" dir="ltr">For Developers</A>‎ &gt; ‎<A href="../design-documents.1.html" dir="ltr">Design Documents</A>‎ &gt; ‎
  </div>
<h3 xmlns="http://www.w3.org/1999/xhtml" id="sites-page-title-header" style="" align="left">
<span id="sites-page-title" dir="ltr" tabindex="-1" style="outline: none">Auto-Throttled Screen Capture and Mirroring</span>
</h3>
<div id="sites-canvas-main" class="sites-canvas-main">
<div id="sites-canvas-main-content">
<table xmlns="http://www.w3.org/1999/xhtml" cellspacing="0" class="sites-layout-name-one-column sites-layout-hbox"><tbody><tr><td class="sites-layout-tile sites-tile-name-content-1"><div dir="ltr"><span><p style="line-height:1.2;margin-top:20pt;margin-bottom:0pt"><span style="font-size:14.6667px;font-weight:700;white-space:pre-wrap;line-height:1.68;background-color:transparent"><font face="arial, sans-serif">Author: Yuri Wiitala (miu@chromium.org)<br /></font></span><span style="font-size:14.6667px;font-weight:700;white-space:pre-wrap;line-height:1.68;background-color:transparent"><font face="arial, sans-serif">Last Updated: September 2015</font></span></p><h1 dir="ltr" style="line-height:1.2;margin-top:24pt;margin-bottom:0pt"><a name="TOC-Background"></a><span style="font-size:21.3333px;font-weight:400;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Background</font></span></h1><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Chromium currently has three built-in screen capture methods (tab content, window, and full desktop) and two video remoting methods (WebRTC/PeerConnection, and Cast Streaming).  Regardless of the combination chosen, the traditional approach to mirroring sessions has been to fix a number of key parameters for the entire session, such as video resolution, maximum frame rate, encoder bit rate, and end-to-end latency (a.k.a. target playout delay, a fixed window of time between frame capture and remote display of the frame).</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">The traditional approach, however, fails to account for a constantly-changing system environment during a mirroring session.  For example, an encoder might become starved for CPU when automated background processes start to run on the sending device.  Another example: Network throughput, latency, and packet loss can wildly fluctuate, especially when using WiFi networks, and especially in crowded environments.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">The traditional approach fails even in ideal environments: Whether it is a Google Engineer shipping default settings (a one size fits all approach) or an end-user customizing settings (often under misconceptions about how the system works), there is no optimal choice.  For example, a video resolution of 1280x720 may be too much for an old laptop to handle, while at the same time a high-performance gaming desktop could easily handle 1920x1080 or higher.  Either way, the user experience is not optimized.</font></span></p><h1 dir="ltr" style="line-height:1.2;margin-top:24pt;margin-bottom:0pt"><a name="TOC-Overview"></a><span style="font-size:21.3333px;font-weight:400;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Overview</font></span></h1><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">This design discusses the goals to be achieved and how the Sender will accomplish those goals by altering parameters while a mirroring session is running.  This document will focus mainly on tab capture, to produce video, and Cast Streaming, to encode and transmit the video to a Receiver (remote device and display).  However, this design should be applicable to other pairings of screen capture type and remoting method.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">The user experience depends on the content being mirrored: interactive content (e.g., slide-show presentations, browsing news articles, browsing photo galleries, and other mostly-static content), and animated content (e.g., movies, sports broadcasts, and other video; and real-time rendered visualizations).</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">For interactive content, the user experience is maximized when end-to-end latency is low, so that user input actions have an immediate result on the remote display; and also when video frame quality is high, so text and/or diagrams are crisp and readable.  Therefore, this design focuses on dropping frames in order to maintain the maximum possible video resolution and encoder target bit rate, all within the hardware constraints of the system.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">For animated content, roughly the opposite is true.  Dropping frames is a very perceivable event and should be avoided at all costs.  Thus, the system should increase end-to-end latency and decrease video frame quality to compensate.  Note that users tend not to perceive small adjustments in video resolution (e.g., a switch between 1280x720 and 1440x810) so long as the smooth video is not interrupted.</font></span></p><h1 dir="ltr" style="line-height:1.2;margin-top:24pt;margin-bottom:0pt"><a name="TOC-Requirements"></a><span style="font-size:21.3333px;font-weight:400;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Requirements</font></span></h1><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Zero configuration:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> Other than hard-coded "sanity bounds," there should be no configuration options exposed to the end-user.  Based on the type of content being mirrored, the system must continuously self-configure to optimize for the user experience.  Performance problems must be detected and abated.  Likewise, where underutilized, the system should take opportunities to improve quality.</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Detect animating content:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> The decisions made by the system depend on knowing what type of content is being mirrored.  In addition, knowing the animation frame rate is critical when calculating new session parameters.</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Avoid extra work:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> Model, predict, and react to upcoming "stalls" before they force the mirroring pipeline (capturer, encoder, etc.) or Receiver to drop a frame.  In other words, a video frame should not be captured if it has no hope of getting transmitted and displayed.</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Support variable media:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> Every component of the mirroring pipeline in the Sender, as well as the Receiver, must support varying the video resolution, frame rate, and encoder bit rate.</span></font></p><h1 dir="ltr" style="line-height:1.2;margin-top:24pt;margin-bottom:0pt"><a name="TOC-Approach"></a><span style="font-size:21.3333px;font-weight:400;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Approach</font></span></h1><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent">The overall approach is to control the data volume of the video being produced by the screen capturer to a point where all components of the mirroring pipeline are operating at a sustainable rate.  As each frame progresses through the pipeline, each component's processing performance is measured for the frame.  Heuristics look at how the performance is trending and trigger reductions (or increases) in data volume by altering the resolution and/or rate of video frames being produced.</span></font></p></span><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><span><div><font face="arial, sans-serif"><div class="sites-embed-align-left-wrapping-off"><div class="sites-embed-border-off sites-embed" style="width:800px;"><div class="sites-embed-object-title" style="display:none;">Auto-Throttled Screen Cap...and Mirroring -- Overview</div><div class="sites-embed-content sites-embed-type-sketchy"><iframe src="https://docs.google.com/drawings/d/1We4o1s0UGX6tMjQBtKZXQ5JzTEKVjnBj8dvoVgYoQ3Y/preview?h=375&amp;hl=en&amp;w=800" width="800" height="375" title="Auto-Throttled Screen Cap...and Mirroring -- Overview" frameborder="0" id="2084618235" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></font></div></span></blockquote></blockquote><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">A video frame is produced by sending the GPU a request to scale a texture and read the result back into a pooled buffer.  Once the read-back is complete, the buffer is handed over to an encoder and then the resulting encoded frame bytes are transmitted over the network to the Receiver.</font></span></p><h3 dir="ltr" style="line-height:1.2;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Measuring-utilization"></a><span style="font-size:16px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Measuring utilization</font></span></h3><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">In order to determine the end-to-end system's capability, the potential bottlenecks in the mirroring pipeline must be monitored, and feedback signals are sent back to the control logic.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">GPU:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> GPUs are optimized for throughput, and the requests made to scale, YUV-convert, and read-back data are internally re-ordered and pipelined.  In addition, it's possible for multiple frame captures to be executing simultaneously within the GPU.  Here's an example timing diagram for frame captures:</span></font></p><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><span><div><font face="arial, sans-serif"><div class="sites-embed-align-left-wrapping-off"><div class="sites-embed-border-off sites-embed" style="width:600px;"><div class="sites-embed-object-title" style="display:none;">Auto-Throttled Screen Cap...d Mirroring -- GPU Timing</div><div class="sites-embed-content sites-embed-type-sketchy"><iframe src="https://docs.google.com/drawings/d/1xIbjE5uJR1qjB6TiQRR5ZC6lsbTqkjEfQIa37zf1tGY/preview?h=350&amp;hl=en&amp;w=600" width="600" height="350" title="Auto-Throttled Screen Cap...d Mirroring -- GPU Timing" frameborder="0" id="2086774251" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></font></div></span></blockquote></blockquote><span><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-family:arial,sans-serif;color:rgb(102,102,102);font-size:14.6667px;white-space:pre-wrap;line-height:1.68;background-color:transparent">[[TBD: Research cause/solution to "Compositor self-throttling" in "Open Issues" section below.  That will likely change our design approach here.]]</span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">One way to measure the GPU's utilization is to measure "lag."  First, the time difference between each successive capture request is noted (e.g., </span><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Frame2Start - Frame1Start</span><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">, and </span><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Frame3Start - Frame2Start</span><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">).  Then, the time difference between each successive capture completion is noted (e.g., </span><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Frame2Finish - Frame1Finish</span><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">, and </span><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Frame3Finish - Frame2Finish</span><span style="font-size:14.6667px;color:rgb(102,102,102);text-decoration:line-through;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">).  The ratio between the two differences is labeled "lag," where a value greater than 100% indicates the GPU is not keeping up with the capture requests.</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Buffer Pool:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> Chromium currently uses a fixed-size video frame buffer pool [and this design decision needs to be revisited to account for differences in available RAM, and greater needs for high frame rate content].  The utilization of the buffer pool is monitored, and when it grows beyond a safety threshold, the system interprets this as an overload signal.  Either frames are being produced at too-fast a rate, frames are not being encoded fast enough, or both.</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Encode time:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> Whether the encoder is a software or hardware-based implementation, the amount of time it takes to encode each frame is measured, relative to the frame's duration.  For a software encoder, this time utilization measurement will indicate whether the Sender's CPU is over-utilized.  A value that exceeds 100% is interpreted as follows: "This frame took longer to encode than the duration it will be shown on the Receiver's display.  If this occurs too often, the pipeline will be forced to drop frames."</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Note that: 1) The measurement must be based on the passage of time according to a high-resolution clock.  2) The measurement accounts for all the effects of thread starvation issues and CPU core availability without having to directly measure these things.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Encode bit rate:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> Network conditions are always changing throughout a session.  Various measurements are taken to estimate network bandwidth and round-trip latency.  The estimates are then used to determine a target encode bit rate.</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Encoders do their best to match the target bit rate, but have to play an up-front "guessing game" with each frame to determine how much entropy will be preserved, and this directly impacts the size of the output.  They usually over- or undershoot the target bit rate, and then remember this error and spread a correction over future frame encodes.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">A naive utilization measurement is to divide the actual bit rate by the target bit rate for each frame.  However, using this to determine a bottleneck in the pipeline is flawed because the encoder is being tasked with the goal of achieving as close to the target bit rate as possible, regardless of the complexity of the input frames.  Thus, a 100% value would rarely indicate encoder output is at a maximum sustainable rate.  Instead, the encoder is just trying to use more bandwidth to maximize quality and could possibly do an acceptable job with less.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Therefore, the encode bit rate utilization needs to be adjusted so that it can be interpreted to mean "the fraction of the target bandwidth </span><span style="font-size:14.6667px;color:rgb(102,102,102);font-weight:700;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">required</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> to encode this frame."  The solution is to account for the complexity of the input frames.  Many encoder implementations, such as libvpx (VP8/VP9), will provide a "quantizer index" value that represents how much of the entropy was discarded when encoding the frame.  Higher quantizer values imply lower quality and smaller output.  The quantizer value was the encoder's guess when it played the "guessing game" described above.  And, the results from using that guess are known (the bit rate utilization).  From these values, the desired utilization measurement can computed as follows:</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif"><code>BitRateUtilization = ActualBitRate / TargetBitRate</code></font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif"><code>IdealQuantizer = BitRateUtilization * ActualQuantizer</code></font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif"><code>UtilizationMeasurement = IdealQuantizer / MaximumValidQuantizer</code></font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Some examples to show how this works:</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Example 1: Let's assume an input frame is too complex to be encoded within the limitation of the current target bit rate.  After the encode is complete, the <code>BitRateUtilization</code> turned out to be 140% and the <code>ActualQuantizer</code> used for the encode was 58.  Thus, the <code>IdealQuantizer</code> is computed to be 81.2, and with a <code>MaximumValidQuantizer</code> of 63 (for VP8), the <code>UtilizationMeasurement</code> is 129%.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Example 2: Let's assume a very simple input frame is being encoded and the encoder uses almost all of the allowed bit rate to maximize quality, but could do well with less bandwidth.  The <code>BitRateUtilization</code> turns out to be 90% and the <code>ActualQuantizer</code> used was 5.  The <code>IdealQuantizer</code> would then be 4.5, and the <code>UtilizationMeasurement</code> is 7%.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent">There are some encoder APIs that do not provide the quantizer, or any similar proxy for it.  In this case, it may be necessary to parse frame headers from the encoded bitstream to extract this information.  If that is not feasible, an implementation will need custom logic to model the encoder's response to the input video and provide the </span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>ActualQuantizer</code></span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> value.</span></font></p><h3 dir="ltr" style="line-height:1.2;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Pre-processing-of-utilization-feedback-signals"></a><span style="font-size:16px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Pre-processing of utilization feedback signals</font></span></h3><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">All utilization signals are in terms of 0% (no load) to 100% (maximum sustainable load), with values greater than 100% indicating a pipeline component will stall or drop frames if the data volume/complexity is not reduced.  These raw signals must be translated into metrics that are actionable by control logic.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Attenuation:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> Running at the "red line" is not a good strategy.  Therefore, all utilization signals should be attenuated so that they are measuring relative to a "comfortable maximum."  This allows the pipeline components some breathing room to be able to process the occasional edge-case frame, one that suddenly takes more processing resources to handle, without actually reaching the true maximum load.</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Time-weighted averaging:</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> The per-frame utilization signals are typically very volatile.  To ensure outlier data points don't trigger premature decisions, all signals are passed through a low-pass filter before being interpreted.  The weighting of the averaging will depend on the volatility and the risk in making bad decisions.</span></font></p><h3 dir="ltr" style="line-height:1.2;margin-top:10pt;margin-bottom:0pt"><a name="TOC-The-actionable-metric:-Capable-pixels-per-frame"></a><span style="font-size:16px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">The actionable metric: Capable pixels per frame</font></span></h3><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Extensive research was performed to determine that the load experienced by all mirroring pipeline components is typically linearly proportional to the number of pixels per second being processed.  In addition, Receiver video quality was tested, both qualitatively and quantitatively, using PSNR and SSIM, and found to also be linearly proportional to the pixel rate, all other parameters fixed.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">One exception is with the encoded output size; and while the result was observed with VP8, it is likely to be the same for other codecs.  The complexity of the content turned out to have a huge factor on the relationship between the output size and the input pixel rate.  For videos with very high entropy (e.g., "Ducks take off from rippling water"), the encoded output size was linearly proportional to the pixel rate.  However, with many typical samples of video (e.g., action movie clips, sports, 3D animation shorts, etc.) the relationship was actually sublinear.  In other words, increasing the input pixel rate by 2X would result in less than a 2X increase in the output size.  The conclusion we draw here is to simply assume the worst case--that relationship is linear--and allow the control logic to converge at an optimum over time.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Thus, only one control "knob," the pixel rate, is needed to ensure every component in the end-to-end system can handle the load.  Two things affect the pixel rate: the frame resolution, and the frame rate.  Of the two, the frame resolution has a much larger impact on the pixel rate and, for animated content, has a lesser impact on the end-user experience.  Any adjustment in capture resolution provides a "squared" increase or decrease in the pixel rate, compared to only a linear change when adjusting the frame rate.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent">So, for now, the design only considers controlling load by changing the capture resolution.  See </span><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Open Issues</span><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"> below for considerations regarding high frame rate content.  The capture resolution is determined by first computing the pipeline-capable number of pixels per frame, as follows:</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><font face="arial, sans-serif"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>PipelineUtilization</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>i</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code> = GREATEST(GpuUtilization</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>i</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>, EncodeTimeUtilization</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>i</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>, …)</code></span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><font face="arial, sans-serif"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>CapablePixels</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>i</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code> = CaptureResolution</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>i</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code> / PipelineUtilization</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>i</code></span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><font face="arial, sans-serif"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>CapablePixelsPerFrame</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>t</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code> = TIME_WEIGHTED_AVERAGE(CapablePixels</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>0</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>, …)</code></span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Note that the frame rate is not a term included in the math above.  However, it is accounted for in the utilization feedback signals: An increasing frame rate would cause the per-frame utilization to increase, depending on how resources such as CPU and network bandwidth are limited.</font></span></p><h3 dir="ltr" style="line-height:1.2;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Deciding-the-capture-resolution"></a><span style="font-size:16px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Deciding the capture resolution</font></span></h3><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Just before requesting the capture of each frame, logic is needed to decide what the resulting frame resolution should be.  In other words, given the size of the source content and the current capable pixels per frame (see above), should the source content be down-scaled and, if so, to what size?</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">First of all, note that the capable pixels per frame can fluctuate frame-to-frame in a rather noisy fashion.  Suppose a naive calculation is used to compute the frame resolution:</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><font face="arial, sans-serif"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>NaiveFrameWidth</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>t</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code> = SQRT(CapablePixelsPerFrame</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>t</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code> * SourceContentAspectRatio)</code></span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt;margin-left:35.25pt"><font face="arial, sans-serif"><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code>NaiveFrameHeight</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>t</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code> = SQRT(CapablePixelsPerFrame</code></span><span style="font-size:7.2px;color:rgb(102,102,102);vertical-align:sub;white-space:pre-wrap;background-color:transparent"><code>t</code></span><span style="font-size:12px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><code> / SourceContentAspectRatio)</code></span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">The above would result in a different frame resolution for each and every frame, with several obvious drawbacks:</font></span></p><ul style="margin-top:0pt;margin-bottom:0pt"><li dir="ltr" style="list-style-type:disc;font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;background-color:transparent"><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Most down-scaling algorithms would have a hard time producing quality results with the peculiar/odd resolutions.  For example, sharp lines and text in the source content image would appear fuzzy and/or distorted in the down-scaled result.</font></span></p></li><li dir="ltr" style="list-style-type:disc;font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;background-color:transparent"><p dir="ltr" style="line-height:1.68;margin-top:0pt;margin-bottom:0pt"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">There would be extra taxing of the CPU because most encoders require an expensive re-initialization whenever frame sizes change.  Also, there would be extra taxing of the available network bandwidth, as most encoders would need to emit a full key frame whenever frame sizes change.</font></span></p></li><li dir="ltr" style="list-style-type:disc;font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;background-color:transparent"><p dir="ltr" style="line-height:1.68;margin-top:0pt;margin-bottom:0pt"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Receivers of the video stream would need to scale the decoded video frames to the resolution of the receiver display.  Again, scaling from odd resolutions to standard display resolutions will produce poor-quality results.  In addition, many receivers have scalers that are performance-optimized only when going between standard resolutions.</font></span></p></li></ul><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Therefore, to mitigate these issues, this design calls for using a fixed set of capture resolutions that have the same aspect ratio as the source content.  Also, capture resolution changes are limited to occur no more than once every three seconds.  The step between nearby capture resolutions must be small enough that the end-user won't notice the difference when a change is made.  However, the step must be large enough to prevent constant flip-flopping between two or more resolutions.  For example, when considering 16:9 source content at 1920x1080, a good step difference is 90 lines.</font></span></p></span><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><span><div><div class="sites-embed-align-left-wrapping-off"><div class="sites-embed-border-off sites-embed" style="width:800px;"><div class="sites-embed-object-title" style="display:none;">Auto-Throttled Screen Cap...ng -- Resolution Decision</div><div class="sites-embed-content sites-embed-type-sketchy"><iframe src="https://docs.google.com/drawings/d/1OXX4NvqrjIFZ0_Co1QZ_edRkv78h8d_HPGHpRabsJ9s/preview?h=125&amp;hl=en&amp;w=800" width="800" height="125" title="Auto-Throttled Screen Cap...ng -- Resolution Decision" frameborder="0" id="578180544" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div></span></blockquote></blockquote><span><div></div><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Now that the inputs and outputs to the decision logic have been well-defined, a strategy for changing resolutions must be described.  At a high-level, the strategy depends on whether the source content is interactive or animating.  When interactive, the goal is to maximize the resolution at the expense of dropping frames.  Therefore, capture resolution changes are allowed every three seconds to reach the highest-supported resolution.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">When source content is animating, a more-complex strategy must be employed since the goal is to provide a smooth capture that avoids dropping frames.  In this case, the strategy is to allow aggressive and immediate decreases in capture resolution in order to preserve frame rate.  Then, if the feedback signals indicate the end-to-end system has been consistently under-utilized for a long (e.g., 30-second) proving period, allow a single step upward in capture resolution.  This strategy avoids rapid flip-flopping which would both: 1) increase the risk of a frame being dropped while the end-to-end system repeatedly adjusts to the new resolutions; and 2) possibly impact the end-user experience, since many repeated resolution changes could become noticeable and bothersome.</font></span></p><h3 dir="ltr" style="line-height:1.2;margin-top:10pt;margin-bottom:0pt"><a name="TOC-Detecting-animating-content"></a><span style="font-size:16px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Detecting animating content</font></span></h3><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Change events are provided by the Chromium compositor as each frame is provided to it by the renderer.  These change events represent candidate frames for capture.  They include both the local presentation timestamp and the damage region within the frame.  For each change event, a decision is made as to whether to request capture of the frame from the GPU.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">In order to determine whether the source content is animating, the recent history of change events is analyzed using on-line heuristics.  Not only is the goal to detect animating content, but to detect the largest region of animating content.  The largest region is important because the user experience is optimized when timing the capture of video frames to those changes.  For example, if the source content is a rendered web page that contains a tiny spinner graphic animating at 60 FPS plus a large video playing at 24 FPS, then the goal of the system is to capture at a rate of 24 FPS:</font></span></p></span><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><blockquote style="margin:0 0 0 40px;border:none;padding:0px"><span><div><div class="sites-embed-align-left-wrapping-off"><div class="sites-embed-border-off sites-embed" style="width:600px;"><div class="sites-embed-object-title" style="display:none;">Auto-Throttled Screen Cap... Animated Content Lock-In</div><div class="sites-embed-content sites-embed-type-sketchy"><iframe src="https://docs.google.com/drawings/d/1yBz5vtteeETSoB8fu-bhsUN_QsKHeONcI57dBXjO-uc/preview?h=625&amp;hl=en&amp;w=600" width="600" height="625" title="Auto-Throttled Screen Cap... Animated Content Lock-In" frameborder="0" id="464823362" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div></span></blockquote></blockquote><span><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><br /></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">In order to accomplish this, the recent history of change events participate in a voting process.  Each change event contributes a vote for its damage region, and that vote is weighted in proportion to the number of pixels in its damage region.  If there is a damage region that gets a supermajority of the votes (i.e., 2/3 or more), it is selected as the overall detected animation region.  Then, the timestamps from all the change events having the same damage region are used to determine the average animation rate.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">There are a number of cases where animation is decidedly not detected.  First, there may be an insufficient history of change events.  Second, the supermajority vote might not be won by any of the candidate damage regions.  Third, when a damage region wins the vote, the change event timestamps must indicate a sequence of regular time periods between events without significant pauses.</font></span></p><h1 dir="ltr" style="line-height:1.2;margin-top:24pt;margin-bottom:0pt"><a name="TOC-Open-Issues"></a><span style="font-size:21.3333px;font-weight:400;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Open Issues</font></span></h1><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Receiver feedback signals</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Everything discussed in the design above for the most part focuses on performance bottlenecks sender-side.  It is worth exploring whether and how to include receiver feedback signals into this design.  One issue is that the latency in the feedback would be much higher, at minimum a full network round-trip time period, and so potential see-sawing effects would have to be mitigated.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">High frame rate content</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">The current design ignores throttling of frame rate.  For the vast majority of typical usage scenarios, this is fine.  However, the exception would be high frame rate content (e.g., 60 FPS).  In this case, a second trade-off needs to be researched: When should the source content be sub-sampled (e.g., 30 FPS) instead of the capture resolution dropped?  In other words, to optimize the user experience, when is it better to drop the frame rate instead of the resolution?</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Adaptive Latency</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">In Cast Streaming, the end-to-end system declares a fixed window of latency between when a video frame would be presented sender-side and the exact moment it is displayed receiver-side.  The default is currently 400 ms, which means capture, encoding, transmission to the receiver, decoding, and presentation are, in-total, allowed to take up to this much time.  The point of this is to allow for any part of the pipeline to occasionally take much longer in processing a frame (e.g., network packets needing re-transmission) without interrupting/glitching the user experience.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">There is research in-progress to identify whether and when it makes sense to dynamically adjust the end-to-end latency throughout a session.  For example, for interactive content, it makes sense to drop the latency so that user input actions on the sender side result in spontaneous responses receiver side.  Likewise, for animating content, it makes sense to increase the latency, effectively adding more "buffering" to the end-to-end system, to help prevent unpredictable events from causing forced frame drops.  In addition, it may or may not become important to account for these latency adjustments with respect to the auto-throttling of capture.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Remoting over the WAN (WebRTC use cases)</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Transmitting the video stream over a wide-area network, and/or broadcasting to multiple receivers introduces additional variance and additional considerations for how feedback utilization signals are generated and used.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Research and work on this issue is being tracked </span><a href="http://crbug.com/516190" style="text-decoration:none"><span style="font-size:14.6667px;color:rgb(17,85,204);text-decoration:underline;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">here</span></a><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent">.</span></font></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Compositor self-throttling</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">There is currently a known issue on lower-end systems: It is possible to achieve a state where animated content is captured from the Chromium compositor, encoded, and remoted without dropping any frames in the capture pipeline; but the frame rate of the source content is actually much higher.  Frames are being dropped because the compositor is under too much load and is reacting by down-throttling the rendering frame rate.  The auto-throttling control logic has no signals making it aware of this fact.  If it were aware, and the tab capture resolution were decreased enough, the load on the compositor would decrease to the point where the rendering frame rate would raise again and match that of the source content.</font></span></p><p dir="ltr" style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><font face="arial, sans-serif"><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent">Research and work on this issue is being tracked </span><a href="http://crbug.com/517714" style="text-decoration:none"><span style="font-size:14.6667px;color:rgb(17,85,204);text-decoration:underline;vertical-align:baseline;white-space:pre-wrap;background-color:transparent">here</span></a><span style="font-size:14.6667px;color:rgb(102,102,102);vertical-align:baseline;white-space:pre-wrap;background-color:transparent">.</span></font></p><h1 dir="ltr" style="line-height:1.2;margin-top:24pt;margin-bottom:0pt"><a name="TOC-Status"></a><span style="font-size:21.3333px;font-weight:400;vertical-align:baseline;white-space:pre-wrap;background-color:transparent"><font face="arial, sans-serif">Status</font></span></h1><p style="line-height:1.68;margin-top:10pt;margin-bottom:0pt"><span style="font-family:arial,sans-serif;color:rgb(102,102,102);font-size:14.6667px;white-space:pre-wrap;line-height:1.68;background-color:transparent">Experiment launched in Chrome 45.  Stable launched in Chrome 46.</span></p><br /></span></div></td></tr></tbody></table>
</div> 
</div> 
<div id="sites-canvas-bottom-panel">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-subpages"> </div>
<div id="sites-attachments-container">
</div>
<a xmlns="http://www.w3.org/1999/xhtml" name="page-comments"></a>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-comments"><div class="sites-comment-docos-wrapper"><div class="sites-comment-docos"><div class="sites-comment-docos-background"></div><div class="sites-comment-docos-header"><div class="sites-comment-docos-header-title">Comments</div></div><div id="sites-comment-docos-pane" class="sites-comment-docos-pane"></div></div></div></div>
</div>
</div> 
</td> 
</tr>
</table> 
</div> 
</div> 
<div id="sites-chrome-footer-wrapper">
<div id="sites-chrome-footer-wrapper-inside">
<div id="sites-chrome-footer">
</div>
</div>
</div>
</div> 
</div> 
<div id="sites-chrome-adminfooter-container">
<div xmlns="http://www.w3.org/1999/xhtml" class="sites-adminfooter" role="navigation"><p><a class="sites-system-link" href="https://www.google.com/a/UniversalLogin?service=jotspot&amp;continue=https://sites.google.com/a/chromium.org/dev/developers/design-documents/auto-throttled-screen-capture-and-mirroring">Sign in</a><span aria-hidden="true">|</span><a class="sites-system-link" href="../../system/app/pages/recentChanges.html">Recent Site Activity</a><span aria-hidden="true">|</span><a class="sites-system-link" href="../../system/app/pages/reportAbuse.html" target="_blank">Report Abuse</a><span aria-hidden="true">|</span><a class="sites-system-link" href="javascript:;" onclick="window.open(webspace.printUrl)">Print Page</a><span aria-hidden="true">|</span><span class="sites-system-link">Powered By</span> <b class="powered-by"><a href="http://sites.google.com">Google Sites</a></b></p></div>
</div>
</div> 
</div> 
<div id="sites-chrome-onebar-footer">
</div>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('sjl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" src="https://ssl.gstatic.com/sites/p/56e332/system/js/jot_min_view__en.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('jl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml">
      
          sites.core.Analytics.createTracker();
          sites.core.Analytics.trackPageview();
        
    </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
                    sites.Searchbox.initialize(
                        'sites-searchbox-search-button',
                        {"object":[]}['object'],
                        'search-site',
                        {"label":"Configure search options...","url":"/system/app/pages/admin/settings"});
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
      gsites.HoverPopupMenu.createSiteDropdownMenus('sites-header-nav-dropdown', false);
    </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("7648876402527094", "Navigation", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_7648876402527094');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("14720868319272995", "Quick links", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_14720868319272995');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("19690813310444355", "Other sites", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_19690813310444355');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
              new sites.CommentPane('//docs.google.com/comments/d/AAHRpnXukca4jaDOG9SuQz_G8t7HllxTRebgkX5D80kwEKA0g965kIWN_nPxl9XsfeR9iiKYG3f9CkNmegWG1yNuf6vPocxQPNI5dqhEoNwWaKqhBd-SkpVaq_1ujEubFlDzXuHZlPRR4/api/js?anon=true',
                  false, false);
            </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
  setTimeout(function() {
    var fingerprint = gsites.date.TimeZone.getFingerprint([]);
    gsites.Xhr.send('https://www.chromium.org/_/tz', null, null, 'GET', null, null, { afjstz: fingerprint });
  }, 500);
</script>
<script xmlns="http://www.w3.org/1999/xhtml">
                    window.onload = function() {
                      if (false) {
                        JOT_setMobilePreview();
                      }
                      var loadTimer = window.jstiming.load;
                      loadTimer.tick("ol");
                      loadTimer["name"] = "load," + webspace.page.type + ",user_page";
                      window.jstiming.report(loadTimer, {}, 'https://gg.google.com/csi');
                    }
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
        JOT_insertAnalyticsCode(false,
            false);
      </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    var maestroRunner = new gsites.pages.view.SitesMaestroRunner(
        webspace, "en");
    maestroRunner.initListeners();
    maestroRunner.installEditRender();
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
  //<![CDATA[
    // Decorate any fastUI buttons on the page with a class of 'goog-button'.
    if (webspace.user.hasWriteAccess) {
      JOT_decorateButtons();
    }

    // Fires delayed events.
    (function() {
      JOT_fullyLoaded = true;
      var delayedEvents = JOT_delayedEvents;
      for (var x = 0; x < delayedEvents.length; x++) {
        var event = delayedEvents[x];
        JOT_postEvent(event.eventName, event.eventSrc, event.payload);
      }
      JOT_delayedEvents = null;
      JOT_postEvent('pageLoaded');
    })();
  //]]>
</script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    JOT_postEvent('decorateGvizCharts');
  </script>
<script type="text/javascript">
          JOT_setupPostRenderingManager();
        </script>
<script type="text/javascript">
          JOT_postEvent('renderPlus', null, 'sites-chrome-main');
        </script>
<div id="server-timer-div" style="display:none"> </div>
<script type="text/javascript">
          window.jstiming.load.tick('render');
          JOT_postEvent('usercontentrendered', this);
        </script>
</body>
</html>
